{
  "dataset/verify.py": [
    {
      "type": "ClassDef",
      "name": "ReturnCode",
      "md_content": [
        "**ReturnCode**: The function of ReturnCode is to define a set of constants representing the various return statuses for file verification operations.\n\n**attributes**: The attributes of this Class.\n· SUCCESS: Indicates that the operation completed successfully.  \n· INTEGRITY_FAILURE: Indicates that a file's integrity check has failed.  \n· FILE_GET_FAILED: Indicates that the attempt to retrieve a file was unsuccessful.  \n· FILE_MISSING_FROM_ONE_HOST: Indicates that a file was not found on one of the specified hosts.  \n· FILES_NOT_EQUAL: Indicates that the files being compared are not identical.  \n· NO_BINARIES_MATCH: Indicates that no binaries matched the specified criteria.  \n· NOT_ENOUGH_GOOD_SIGS: Indicates that there are not enough trusted signatures to meet the required threshold.  \n· BINARY_DOWNLOAD_FAILED: Indicates that the download of a binary file has failed.  \n· BAD_VERSION: Indicates that the version provided is not acceptable or is incorrectly formatted.  \n\n**Code Description**: The ReturnCode class is an enumeration that extends the functionality of the built-in IntEnum class from the enum module. It provides a clear and organized way to represent various return codes that can be used throughout the dataset verification process. Each attribute corresponds to a specific outcome of operations related to file retrieval, integrity checks, and signature verification.\n\nThis class is utilized in several functions within the dataset/verify.py module, including get_files_from_hosts_and_compare, verify_shasums_signature, verify_binary_hashes, verify_published_handler, and verify_binaries_handler. Each of these functions returns a ReturnCode value to indicate the result of their operations. For instance, if a file cannot be retrieved from a host, the function will return ReturnCode.FILE_GET_FAILED. Similarly, if the integrity of a file fails, ReturnCode.INTEGRITY_FAILURE will be returned.\n\nThe use of ReturnCode enhances code readability and maintainability by providing meaningful names for return values instead of using arbitrary integers. This allows developers to quickly understand the outcome of operations without needing to reference documentation or comments extensively.\n\n**Note**: When using the ReturnCode class, it is essential to handle each return value appropriately in the calling functions to ensure that errors are logged and managed correctly. This practice helps maintain the robustness of the verification process and provides clear feedback to users regarding the status of their operations."
      ],
      "code_start_line": 56,
      "code_end_line": 65,
      "params": [],
      "have_return": false,
      "code_content": "class ReturnCode(enum.IntEnum):\n    SUCCESS = 0\n    INTEGRITY_FAILURE = 1\n    FILE_GET_FAILED = 4\n    FILE_MISSING_FROM_ONE_HOST = 5\n    FILES_NOT_EQUAL = 6\n    NO_BINARIES_MATCH = 7\n    NOT_ENOUGH_GOOD_SIGS = 9\n    BINARY_DOWNLOAD_FAILED = 10\n    BAD_VERSION = 11\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "dataset/verify.py/get_files_from_hosts_and_compare",
        "dataset/verify.py/verify_shasums_signature",
        "dataset/verify.py/verify_binary_hashes",
        "dataset/verify.py/verify_published_handler",
        "dataset/verify.py/verify_binaries_handler"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "set_up_logger",
      "md_content": [
        "**set_up_logger**: The function of set_up_logger is to configure a logger that outputs log messages to standard error (stderr).\n\n**parameters**: The parameters of this Function.\n· is_verbose: A boolean value that determines the logging level. If set to True, the logger will log informational messages; if set to False, it will log warnings and above.\n\n**Code Description**: The set_up_logger function initializes a logger using Python's logging module. It first retrieves a logger instance associated with the current module using `logging.getLogger(__name__)`. The logging level is set based on the is_verbose parameter: if is_verbose is True, the logging level is set to INFO, allowing informational messages to be logged; if False, the level is set to WARNING, which restricts logging to warning messages and errors only. \n\nNext, a StreamHandler is created to direct log messages to standard error (stderr). This handler is set to DEBUG level, meaning it will process all messages at this level and above. A formatter is then defined to structure the log messages, which will display the log level and the message in the format '[LEVEL] message'. The formatter is applied to the console handler, and the handler is added to the logger. Finally, the configured logger instance is returned for use in other parts of the application.\n\n**Note**: It is important to ensure that the logging configuration does not conflict with other logging setups in the application. The is_verbose parameter allows for easy toggling between detailed and concise logging output.\n\n**Output Example**: When is_verbose is set to True and a log message is generated, the output might appear as:\n```\n[INFO] This is an informational message.\n```\nIf is_verbose is set to False, the output for a warning message would be:\n```\n[WARNING] This is a warning message.\n```"
      ],
      "code_start_line": 68,
      "code_end_line": 77,
      "params": [
        "is_verbose"
      ],
      "have_return": true,
      "code_content": "def set_up_logger(is_verbose: bool = True) -> logging.Logger:\n    \"\"\"Set up a logger that writes to stderr.\"\"\"\n    log = logging.getLogger(__name__)\n    log.setLevel(logging.INFO if is_verbose else logging.WARNING)\n    console = logging.StreamHandler(sys.stderr)  # log to stderr\n    console.setLevel(logging.DEBUG)\n    formatter = logging.Formatter('[%(levelname)s] %(message)s')\n    console.setFormatter(formatter)\n    log.addHandler(console)\n    return log\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "indent",
      "md_content": [
        "**indent**: The function of indent is to add indentation to a given string output.\n\n**parameters**: The parameters of this Function.\n· output: A string that represents the text to which indentation will be added.\n\n**Code Description**: The indent function utilizes the textwrap module's indent method to prepend a specified string (in this case, two spaces) to each line of the provided output string. This function is particularly useful for formatting text output, making it more readable by visually distinguishing it from other text. \n\nThe indent function is called in several other functions within the dataset/verify.py module. For instance, in the files_are_equal function, it is used to format the output of the diff between two files when they are found to be unequal. This enhances the clarity of the log messages by ensuring that the differences are easily identifiable.\n\nSimilarly, in the get_files_from_hosts_and_compare function, the indent function is employed to format the output from the wget command when a file download fails. This ensures that error messages are presented in a structured manner, making it easier for developers to diagnose issues.\n\nIn the check_multisig function, the indent function is used to format the output from the GPG verification process when verbose logging is enabled. This allows users to see the GPG output in a more organized way, improving the readability of the logs.\n\nLastly, in the verify_shasums_signature function, the indent function formats the GPG output when an integrity failure occurs. This consistent use of indentation across various functions helps maintain a uniform logging style throughout the module.\n\n**Note**: When using the indent function, ensure that the output string is properly formatted to avoid unexpected results. The function assumes that the input is a string and does not handle cases where the input may be of a different type.\n\n**Output Example**: If the input to the indent function is:\n```\n\"Line 1\\nLine 2\\nLine 3\"\n```\nThe output will be:\n```\n\"  Line 1\\n  Line 2\\n  Line 3\"\n```"
      ],
      "code_start_line": 83,
      "code_end_line": 84,
      "params": [
        "output"
      ],
      "have_return": true,
      "code_content": "def indent(output: str) -> str:\n    return textwrap.indent(output, '  ')\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "dataset/verify.py/files_are_equal",
        "dataset/verify.py/get_files_from_hosts_and_compare",
        "dataset/verify.py/check_multisig",
        "dataset/verify.py/verify_shasums_signature",
        "dataset/verify.py/verify_published_handler"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "bool_from_env",
      "md_content": [
        "**bool_from_env**: The function of bool_from_env is to retrieve a boolean value from the environment variables based on a specified key.\n\n**parameters**: The parameters of this Function.\n· parameter1: key - A string representing the name of the environment variable to check.\n· parameter2: default - A boolean value that serves as the fallback if the specified key is not found in the environment variables. The default value is set to False.\n\n**Code Description**: The bool_from_env function checks if a specified key exists in the environment variables. If the key is not present, it returns the default value provided as a parameter. If the key is found, it retrieves the corresponding value and converts it to lowercase for comparison. The function recognizes the strings '1' and 'true' as True, while '0' and 'false' are interpreted as False. If the value does not match any of these recognized strings, the function raises a ValueError, indicating that the environment variable contains an unrecognized value.\n\nThis function is utilized within the main function of the dataset/verify.py module. It is called multiple times to set default values for various command-line arguments based on the corresponding environment variables. For instance, the verbosity level, quiet mode, and JSON output options are all determined by the values of environment variables such as 'BINVERIFY_VERBOSE', 'BINVERIFY_QUIET', and 'BINVERIFY_JSON', respectively. This design allows for flexible configuration of the program's behavior through environment variables, enhancing usability and adaptability in different execution contexts.\n\n**Note**: It is important to ensure that the environment variable values are strictly '1', 'true', '0', or 'false' to avoid triggering the ValueError. Users should be aware of the expected formats when setting environment variables to prevent runtime errors.\n\n**Output Example**: If the environment variable 'BINVERIFY_VERBOSE' is set to 'true', the function call bool_from_env('BINVERIFY_VERBOSE') will return True. If the variable is not set, it will return False as the default value."
      ],
      "code_start_line": 87,
      "code_end_line": 96,
      "params": [
        "key",
        "default"
      ],
      "have_return": true,
      "code_content": "def bool_from_env(key, default=False) -> bool:\n    if key not in os.environ:\n        return default\n    raw = os.environ[key]\n\n    if raw.lower() in ('1', 'true'):\n        return True\n    elif raw.lower() in ('0', 'false'):\n        return False\n    raise ValueError(f\"Unrecognized environment value {key}={raw!r}\")\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "dataset/verify.py/main"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "parse_version_string",
      "md_content": [
        "**parse_version_string**: The function of parse_version_string is to parse a version string into its base version, release candidate (if applicable), and operating system/platform information.\n\n**parameters**: The parameters of this Function.\n· version_str: A string representing the version, which may include a release candidate suffix and/or platform information.\n\n**Code Description**: The parse_version_string function takes a version string formatted in a specific way and splits it into three components: the base version, the release candidate (if present), and the operating system or platform information. The function first splits the input string using the hyphen ('-') as a delimiter. The first part of the split string is always considered the base version. Depending on the number of parts obtained from the split, the function determines whether there is a release candidate or platform information. \n\nIf the input string contains two parts, it checks if the second part includes \"rc\" to identify it as a release candidate; otherwise, it is treated as platform information. If there are three parts, the second part is assigned to the release candidate and the third part to the platform information. The function then returns a tuple containing the base version, release candidate, and platform information.\n\nThis function is called within the verify_published_handler function, which is responsible for verifying published binaries based on the provided version string. The parse_version_string function is crucial in this context as it extracts the necessary components from the version string to determine the appropriate remote directory for fetching binaries and signatures. The successful parsing of the version string is essential for the subsequent operations in verify_published_handler, such as constructing the remote directory path and managing the verification process.\n\n**Note**: It is important to ensure that the version string provided to the parse_version_string function adheres to the expected format, as deviations may lead to exceptions being raised during parsing.\n\n**Output Example**: For an input string \"1.0.0-rc1-linux\", the function would return the tuple: (\"1.0.0\", \"rc1\", \"linux\")."
      ],
      "code_start_line": 102,
      "code_end_line": 116,
      "params": [
        "version_str"
      ],
      "have_return": true,
      "code_content": "def parse_version_string(version_str):\n    parts = version_str.split('-')\n    version_base = parts[0]\n    version_rc = \"\"\n    version_os = \"\"\n    if len(parts) == 2:  # \"<version>-rcN\" or \"version-platform\"\n        if \"rc\" in parts[1]:\n            version_rc = parts[1]\n        else:\n            version_os = parts[1]\n    elif len(parts) == 3:  # \"<version>-rcN-platform\"\n        version_rc = parts[1]\n        version_os = parts[2]\n\n    return version_base, version_rc, version_os\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "dataset/verify.py/verify_published_handler"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "download_with_wget",
      "md_content": [
        "**download_with_wget**: The function of download_with_wget is to download a file from a specified remote location and save it to a local file path using the wget command-line utility.\n\n**parameters**: The parameters of this Function.\n· remote_file: A string representing the URL of the file to be downloaded.\n· local_file: A string representing the path where the downloaded file will be saved locally.\n\n**Code Description**: The download_with_wget function utilizes the subprocess module to execute the wget command, which is a widely used utility for downloading files from the web. The function constructs a command that includes the remote file URL and the local file path where the downloaded content should be stored. It runs this command and captures both the standard output and standard error. The function returns a tuple containing a boolean indicating the success of the download operation and the decoded output from the wget command, stripped of any trailing whitespace.\n\nThis function is called by other functions in the project, specifically get_files_from_hosts_and_compare and verify_published_handler. In get_files_from_hosts_and_compare, download_with_wget is used to retrieve files from multiple hosts, ensuring that the files are identical across these sources. The success of the download is critical for the subsequent comparison of file contents. In verify_published_handler, download_with_wget is employed to download binary files after verifying their signatures and checksums, ensuring that the correct files are obtained for further verification processes. The successful execution of download_with_wget is essential for the overall integrity and reliability of the file verification workflow in the project.\n\n**Note**: It is important to ensure that the wget utility is installed and accessible in the environment where this function is executed. Additionally, the remote URL must be valid and reachable to avoid download failures.\n\n**Output Example**: A possible return value of the function could be (True, \"Downloaded 1234 bytes in 0.5 seconds\"), indicating that the download was successful and providing information about the download size and time."
      ],
      "code_start_line": 119,
      "code_end_line": 122,
      "params": [
        "remote_file",
        "local_file"
      ],
      "have_return": true,
      "code_content": "def download_with_wget(remote_file, local_file):\n    result = subprocess.run(['wget', '-O', local_file, remote_file],\n                            stderr=subprocess.STDOUT, stdout=subprocess.PIPE)\n    return result.returncode == 0, result.stdout.decode().rstrip()\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "dataset/verify.py/get_files_from_hosts_and_compare",
        "dataset/verify.py/verify_published_handler"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "download_lines_with_urllib",
      "md_content": [
        "**download_lines_with_urllib**: The function of download_lines_with_urllib is to retrieve text lines from a specified URL over HTTP.\n\n**parameters**: The parameters of this Function.\n· url: A string representing the URL from which to download the text lines.\n\n**Code Description**: The download_lines_with_urllib function attempts to open a specified URL and read its content line by line. It utilizes the urllib library to perform an HTTP request. The function returns a tuple containing a boolean value and a list of strings. If the request is successful, the boolean value is True, and the list contains the stripped lines of text retrieved from the URL. Each line is decoded from bytes to a string format. If an HTTP error occurs, such as a 404 or 500 status code, the function catches the urllib.error.HTTPError exception and logs a warning message indicating the failure. Additionally, if any other exception occurs during the request, it is caught, and a warning is logged as well. In both cases of failure, the function returns a tuple with the boolean value set to False and an empty list.\n\n**Note**: It is important to ensure that the URL provided is valid and accessible. The function handles exceptions gracefully, logging warnings for any errors encountered during the HTTP request.\n\n**Output Example**: A successful call to download_lines_with_urllib(\"http://example.com/file.txt\") might return:\n(True, ['First line of text', 'Second line of text', 'Third line of text']) \n\nConversely, if the URL is invalid or an error occurs, it might return:\n(False, [])"
      ],
      "code_start_line": 125,
      "code_end_line": 134,
      "params": [
        "url"
      ],
      "have_return": true,
      "code_content": "def download_lines_with_urllib(url) -> t.Tuple[bool, t.List[str]]:\n    \"\"\"Get (success, text lines of a file) over HTTP.\"\"\"\n    try:\n        return (True, [\n            line.strip().decode() for line in urllib.request.urlopen(url).readlines()])\n    except urllib.error.HTTPError as e:\n        log.warning(f\"HTTP request to {url} failed (HTTPError): {e}\")\n    except Exception as e:\n        log.warning(f\"HTTP request to {url} failed ({e})\")\n    return (False, [])\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "verify_with_gpg",
      "md_content": [
        "**verify_with_gpg**: The function of verify_with_gpg is to verify the authenticity of a file using GPG signatures.\n\n**parameters**: The parameters of this Function.\n· filename: The path to the file that needs to be verified.\n· signature_filename: The path to the GPG signature file associated with the file being verified.\n· output_filename: An optional parameter specifying the path where the output should be written. If not provided, the output will not be written to a file.\n\n**Code Description**: The verify_with_gpg function utilizes the GPG (GNU Privacy Guard) command-line tool to verify the signature of a specified file. It constructs a command with the necessary arguments to invoke GPG, including options to handle the verification process and specify the output format. The function creates a temporary file to capture the status output from GPG during the verification process.\n\nThe function begins by creating a temporary file using `tempfile.NamedTemporaryFile()` to store the status messages generated by GPG. It then constructs the command-line arguments for the GPG verification, including options to display only the primary UID and to specify the output file for the verification results. The environment variable `LANGUAGE` is set to 'en' to ensure that the output is in English.\n\nThe subprocess module is used to execute the GPG command, capturing both standard output and error output. After the command execution, the status file is read to obtain the GPG output, which is then decoded and stripped of any trailing whitespace.\n\nThe function logs the return code and the output from GPG for debugging purposes and returns a tuple containing the GPG return code and the status output. A return code of '0' typically indicates a successful verification, while other codes indicate various error states.\n\nThis function is called by the check_multisig function, which is responsible for checking the signatures of multiple files. In check_multisig, verify_with_gpg is invoked to validate the signature of a sums file against a provided signature file. The output from verify_with_gpg is then parsed to determine the status of the signatures (good, unknown, or bad). If there are unknown signatures and the user opts to import keys, the function attempts to retrieve the necessary keys before re-verifying the signatures.\n\n**Note**: It is important to ensure that GPG is installed and properly configured on the system where this function is executed. Additionally, the output_filename parameter should be used with caution, as providing an invalid path may lead to errors during execution.\n\n**Output Example**: A possible return value from the function could be (0, \"gpg: Good signature from 'John Doe <john@example.com>'\"), indicating a successful verification with a message confirming the good signature."
      ],
      "code_start_line": 137,
      "code_end_line": 154,
      "params": [
        "filename",
        "signature_filename",
        "output_filename"
      ],
      "have_return": true,
      "code_content": "def verify_with_gpg(\n    filename,\n    signature_filename,\n    output_filename: t.Optional[str] = None\n) -> t.Tuple[int, str]:\n    with tempfile.NamedTemporaryFile() as status_file:\n        args = [\n            'gpg', '--yes', '--verify', '--verify-options', 'show-primary-uid-only', \"--status-file\", status_file.name,\n            '--output', output_filename if output_filename else '', signature_filename, filename]\n\n        env = dict(os.environ, LANGUAGE='en')\n        result = subprocess.run(args, stderr=subprocess.STDOUT, stdout=subprocess.PIPE, env=env)\n\n        gpg_data = status_file.read().decode().rstrip()\n\n    log.debug(f'Result from GPG ({result.returncode}): {result.stdout.decode()}')\n    log.debug(f\"{gpg_data}\")\n    return result.returncode, gpg_data\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "dataset/verify.py/check_multisig"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "remove_files",
      "md_content": [
        "**remove_files**: The function of remove_files is to delete files specified in a list of filenames.\n\n**parameters**: The parameters of this Function.\n· parameter1: filenames - A list of strings, where each string represents the name of a file to be removed from the filesystem.\n\n**Code Description**: The remove_files function iterates over a list of filenames provided as an argument. For each filename in the list, it calls the os.remove() function to delete the corresponding file from the filesystem. This function assumes that the filenames provided are valid and that the files exist; otherwise, an exception will be raised if a file cannot be found or accessed.\n\nThe function does not return any value. It performs the operation of file deletion directly. It is important to ensure that the list of filenames does not contain any unintended files, as this operation is irreversible and will permanently remove the specified files from the system.\n\n**Note**: Points to note about the use of the code\n- Ensure that the filenames provided are correct and that the files exist to avoid exceptions.\n- Consider implementing error handling to manage cases where a file cannot be deleted, such as using try-except blocks around the os.remove() call.\n- Be cautious when using this function, as it will permanently delete files without any confirmation or recovery option."
      ],
      "code_start_line": 157,
      "code_end_line": 159,
      "params": [
        "filenames"
      ],
      "have_return": false,
      "code_content": "def remove_files(filenames):\n    for filename in filenames:\n        os.remove(filename)\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "ClassDef",
      "name": "SigData",
      "md_content": [
        "**SigData**: The function of SigData is to represent GPG signature data parsed from GPG stdout.\n\n**attributes**: The attributes of this Class.\n· key: Represents the unique identifier of the GPG key associated with the signature. It can be None if not set.\n· name: A string that holds the name of the entity associated with the signature.\n· trusted: A boolean indicating whether the signature is trusted or not.\n· status: A string that describes the status of the signature, such as \"expired\" or \"revoked\".\n\n**Code Description**: The SigData class is designed to encapsulate the details of a GPG signature, including the key, name, trust status, and any relevant status messages. The constructor initializes the attributes to default values, with `key` set to None, `name` as an empty string, `trusted` as False, and `status` as an empty string. \n\nThe class includes a `__bool__` method that allows instances of SigData to be evaluated in a boolean context. This method returns True if the `key` attribute is not None, indicating that the signature data is valid. The `__repr__` method provides a string representation of the SigData instance, which includes the values of its attributes, formatted for clarity.\n\nThe SigData class is utilized within the context of signature verification processes in the project. It is primarily called by functions such as `parse_gpg_result`, `check_multisig`, and `verify_shasums_signature`. The `parse_gpg_result` function processes the output from GPG, creating instances of SigData for good, unknown, and bad signatures. These instances are then returned as lists to the calling functions, which further handle the verification logic, including checking the trustworthiness of the signatures and logging the results.\n\n**Note**: When using the SigData class, it is important to ensure that the `key` attribute is set appropriately to reflect the actual GPG key being represented. The trust status and signature status should also be updated based on the results of the GPG verification process.\n\n**Output Example**: An instance of SigData might be represented as follows:\nSigData('A1B2C3D4', 'John Doe', trusted=True, status='')"
      ],
      "code_start_line": 162,
      "code_end_line": 176,
      "params": [],
      "have_return": true,
      "code_content": "class SigData:\n    \"\"\"GPG signature data as parsed from GPG stdout.\"\"\"\n    def __init__(self):\n        self.key = None\n        self.name = \"\"\n        self.trusted = False\n        self.status = \"\"\n\n    def __bool__(self):\n        return self.key is not None\n\n    def __repr__(self):\n        return (\n            \"SigData(%r, %r, trusted=%s, status=%r)\" %\n            (self.key, self.name, self.trusted, self.status))\n",
      "name_column": 6,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "dataset/verify.py/parse_gpg_result",
        "dataset/verify.py/check_multisig",
        "dataset/verify.py/verify_shasums_signature"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "__init__",
      "md_content": [
        "**__init__**: The function of __init__ is to initialize an instance of the SigData class with default attribute values.\n\n**parameters**: The parameters of this Function.\n· There are no parameters for this function.\n\n**Code Description**: The __init__ function is a constructor method that is automatically called when an instance of the SigData class is created. This function initializes four attributes of the class: \n- `self.key`: This attribute is set to None, indicating that it does not hold any value upon initialization. It is likely intended to store a key value that may be assigned later in the object's lifecycle.\n- `self.name`: This attribute is initialized as an empty string. It is intended to hold the name associated with the SigData instance, which can be populated with a meaningful string later.\n- `self.trusted`: This attribute is set to False, indicating that the instance is not trusted by default. This boolean value may be used to determine the trustworthiness of the data represented by the instance.\n- `self.status`: This attribute is also initialized as an empty string. It is meant to represent the current status of the SigData instance, which can be updated as needed.\n\nOverall, the __init__ function establishes a clean state for the SigData object, ensuring that all attributes are defined and ready for use.\n\n**Note**: It is important to remember that this constructor does not take any parameters, meaning that any specific values for the attributes must be set after the object is instantiated. Users of this class should ensure that they assign appropriate values to these attributes to avoid operating with default states that may not be suitable for their use case."
      ],
      "code_start_line": 164,
      "code_end_line": 168,
      "params": [
        "self"
      ],
      "have_return": false,
      "code_content": "    def __init__(self):\n        self.key = None\n        self.name = \"\"\n        self.trusted = False\n        self.status = \"\"\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "__bool__",
      "md_content": [
        "**__bool__**: The function of __bool__ is to determine the truthiness of an instance of the SigData class.\n\n**parameters**: The parameters of this Function.\n· There are no parameters for this function.\n\n**Code Description**: The __bool__ function is a special method in Python that is used to define the truth value of an object. In this implementation, the function checks if the attribute `key` of the instance is not `None`. If `self.key` is not `None`, the function returns `True`, indicating that the instance is considered \"truthy\". Conversely, if `self.key` is `None`, the function returns `False`, indicating that the instance is considered \"falsy\". This behavior allows instances of the SigData class to be used in conditional statements and boolean contexts, providing a clear and intuitive way to evaluate the state of the object based on the presence of the `key` attribute.\n\n**Note**: It is important to ensure that the `key` attribute is properly initialized before using this method, as its value directly affects the truthiness of the instance. If `key` is expected to be `None` at certain times, the behavior of the instance in boolean contexts should be understood accordingly.\n\n**Output Example**: \n- If an instance of SigData has `key` set to a valid value (e.g., `key = \"some_value\"`), calling `bool(instance)` will return `True`.\n- If `key` is set to `None` (e.g., `key = None`), calling `bool(instance)` will return `False`."
      ],
      "code_start_line": 170,
      "code_end_line": 171,
      "params": [
        "self"
      ],
      "have_return": true,
      "code_content": "    def __bool__(self):\n        return self.key is not None\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "__repr__",
      "md_content": [
        "**__repr__**: The function of __repr__ is to provide a string representation of the SigData object.\n\n**parameters**: The parameters of this Function.\n· There are no parameters for this function.\n\n**Code Description**: The __repr__ method is a special method in Python that is used to define a string representation for an instance of a class. In this implementation, the method returns a formatted string that includes the key attributes of the SigData object. Specifically, it returns a string that contains the class name \"SigData\" followed by the values of the object's attributes: `key`, `name`, `trusted`, and `status`. The attributes are formatted using the `%r` format specifier, which calls the `repr()` function on the attributes, ensuring that they are represented in a way that is unambiguous and suitable for debugging. The `trusted` attribute is formatted as a boolean value, while the others are represented in their respective formats.\n\n**Note**: It is important to ensure that the attributes `key`, `name`, `trusted`, and `status` are defined within the SigData class for this method to function correctly. This method is particularly useful for debugging and logging, as it provides a clear and concise representation of the object.\n\n**Output Example**: An example of the output from this method could be:\n\"SigData('12345', 'Sample Data', trusted=True, status='active')\""
      ],
      "code_start_line": 173,
      "code_end_line": 176,
      "params": [
        "self"
      ],
      "have_return": true,
      "code_content": "    def __repr__(self):\n        return (\n            \"SigData(%r, %r, trusted=%s, status=%r)\" %\n            (self.key, self.name, self.trusted, self.status))\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "parse_gpg_result",
      "md_content": [
        "**parse_gpg_result**: The function of parse_gpg_result is to parse the output from GPG and return categorized lists of good, unknown, and bad signatures.\n\n**parameters**: The parameters of this Function.\n· output: A list of strings representing the lines of output from GPG.\n\n**Code Description**: The parse_gpg_result function processes the output from GPG, which is expected to contain information about various signatures associated with a file. It categorizes these signatures into three distinct lists: good signatures, unknown signatures, and bad signatures. The function begins by initializing three lists to hold instances of the SigData class, which encapsulates the details of each signature.\n\nThe function defines a nested helper function, line_begins_with, which checks if a given line starts with a specific pattern. This is crucial for ensuring that the parser only processes lines that are relevant and prevents malicious input from affecting the parsing logic.\n\nAs the function iterates through each line of the GPG output, it uses regular expressions to identify and categorize the signatures based on specific prefixes such as \"NEWSIG\", \"GOODSIG\", \"BADSIG\", and others. For each identified signature, it populates the attributes of a SigData instance, including the key, name, trust status, and any relevant status messages (e.g., \"expired\" or \"revoked\"). \n\nAt the end of the parsing process, the function checks that the total number of resolved signatures matches the number of signatures found in the output. If there is a discrepancy, it raises a RuntimeError to alert the caller of the issue.\n\nThe parse_gpg_result function is called by the check_multisig function, which is responsible for verifying signatures against a given file. After obtaining the output from GPG, check_multisig calls parse_gpg_result to categorize the signatures, allowing it to handle unknown signatures appropriately, such as prompting the user to retrieve missing keys.\n\n**Note**: When using parse_gpg_result, it is essential to ensure that the output provided is correctly formatted as expected by the function. Any deviations in the output format may lead to incorrect parsing or runtime errors.\n\n**Output Example**: The return value of parse_gpg_result could look like this:\n(\n    [SigData('A1B2C3D4', 'John Doe', trusted=True, status='')],\n    [SigData('E5F6G7H8', 'Unknown Entity', trusted=False, status='')],\n    [SigData('I9J0K1L2', 'Malicious Entity', trusted=False, status='revoked')]\n)"
      ],
      "code_start_line": 179,
      "code_end_line": 244,
      "params": [
        "output"
      ],
      "have_return": true,
      "code_content": "def parse_gpg_result(\n    output: t.List[str]\n) -> t.Tuple[t.List[SigData], t.List[SigData], t.List[SigData]]:\n    \"\"\"Returns good, unknown, and bad signatures from GPG stdout.\"\"\"\n    good_sigs: t.List[SigData] = []\n    unknown_sigs: t.List[SigData] = []\n    bad_sigs: t.List[SigData] = []\n    total_resolved_sigs = 0\n\n    # Ensure that all lines we match on include a prefix that prevents malicious input\n    # from fooling the parser.\n    def line_begins_with(patt: str, line: str) -> t.Optional[re.Match]:\n        return re.match(r'^(\\[GNUPG:\\])\\s+' + patt, line)\n\n    curr_sigs = unknown_sigs\n    curr_sigdata = SigData()\n\n    for line in output:\n        if line_begins_with(r\"NEWSIG(?:\\s|$)\", line):\n            total_resolved_sigs += 1\n            if curr_sigdata:\n                curr_sigs.append(curr_sigdata)\n                curr_sigdata = SigData()\n            newsig_split = line.split()\n            if len(newsig_split) == 3:\n                curr_sigdata.name = newsig_split[2]\n\n        elif line_begins_with(r\"GOODSIG(?:\\s|$)\", line):\n            curr_sigdata.key, curr_sigdata.name = line.split(maxsplit=3)[2:4]\n            curr_sigs = good_sigs\n\n        elif line_begins_with(r\"EXPKEYSIG(?:\\s|$)\", line):\n            curr_sigdata.key, curr_sigdata.name = line.split(maxsplit=3)[2:4]\n            curr_sigs = good_sigs\n            curr_sigdata.status = \"expired\"\n\n        elif line_begins_with(r\"REVKEYSIG(?:\\s|$)\", line):\n            curr_sigdata.key, curr_sigdata.name = line.split(maxsplit=3)[2:4]\n            curr_sigs = good_sigs\n            curr_sigdata.status = \"revoked\"\n\n        elif line_begins_with(r\"BADSIG(?:\\s|$)\", line):\n            curr_sigdata.key, curr_sigdata.name = line.split(maxsplit=3)[2:4]\n            curr_sigs = bad_sigs\n\n        elif line_begins_with(r\"ERRSIG(?:\\s|$)\", line):\n            curr_sigdata.key, _, _, _, _, _ = line.split()[2:8]\n            curr_sigs = unknown_sigs\n\n        elif line_begins_with(r\"TRUST_(UNDEFINED|NEVER)(?:\\s|$)\", line):\n            curr_sigdata.trusted = False\n\n        elif line_begins_with(r\"TRUST_(MARGINAL|FULLY|ULTIMATE)(?:\\s|$)\", line):\n            curr_sigdata.trusted = True\n\n    # The last one won't have been added, so add it now\n    assert curr_sigdata\n    curr_sigs.append(curr_sigdata)\n\n    all_found = len(good_sigs + bad_sigs + unknown_sigs)\n    if all_found != total_resolved_sigs:\n        raise RuntimeError(\n            f\"failed to evaluate all signatures: found {all_found} \"\n            f\"but expected {total_resolved_sigs}\")\n\n    return (good_sigs, unknown_sigs, bad_sigs)\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "dataset/verify.py/check_multisig"
      ],
      "reference_who": [
        "dataset/verify.py/SigData"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "line_begins_with",
      "md_content": [
        "**line_begins_with**: The function of line_begins_with is to determine if a given line starts with a specific pattern prefixed by the string \"[GNUPG:]\".\n\n**parameters**: The parameters of this Function.\n· parameter1: patt - A string representing the pattern that the line should match after the \"[GNUPG:]\" prefix.  \n· parameter2: line - A string that represents the line to be checked against the specified pattern.\n\n**Code Description**: The line_begins_with function utilizes the re.match method from the regular expression module (re) to check if the input line begins with the specified pattern. The function constructs a regular expression that looks for the exact string \"[GNUPG:]\" followed by one or more whitespace characters and then the provided pattern (patt). The caret (^) in the regular expression signifies that the match must occur at the start of the line. If the line matches this constructed pattern, re.match returns a match object; otherwise, it returns None. This function is particularly useful for parsing lines of text that are expected to follow a specific format, such as log entries from GnuPG.\n\n**Note**: It is important to ensure that the pattern provided in the patt parameter is a valid regular expression. Additionally, the function only checks for matches at the beginning of the line, so any content before \"[GNUPG:]\" will result in no match.\n\n**Output Example**: If the line is \"[GNUPG:] key 12345\" and the pattern is \"key\", the function will return a match object. If the line is \"key 12345\" (without the \"[GNUPG:]\" prefix), the function will return None."
      ],
      "code_start_line": 190,
      "code_end_line": 191,
      "params": [
        "patt",
        "line"
      ],
      "have_return": true,
      "code_content": "    def line_begins_with(patt: str, line: str) -> t.Optional[re.Match]:\n        return re.match(r'^(\\[GNUPG:\\])\\s+' + patt, line)\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "files_are_equal",
      "md_content": [
        "**files_are_equal**: The function of files_are_equal is to compare the contents of two files and determine if they are identical.\n\n**parameters**: The parameters of this Function.\n· filename1: A string representing the path to the first file to be compared.\n· filename2: A string representing the path to the second file to be compared.\n\n**Code Description**: The files_are_equal function opens two files in binary mode and reads their contents to compare them for equality. If the contents are identical, the function returns True. If the contents differ, it proceeds to open both files in text mode, reads their lines, and generates a unified diff of the differences using the difflib module. This diff is then indented for better readability and logged as a warning message, indicating the files that were found to be different. The function ultimately returns False in this case.\n\nThis function is called by the get_files_from_hosts_and_compare function, which is responsible for retrieving files from multiple hosts and ensuring that they are identical. After downloading files from the specified hosts, get_files_from_hosts_and_compare invokes files_are_equal to compare each downloaded file with the next one in the list. If any pair of files is found to be unequal, an error is logged, and the function returns a specific return code indicating that the files are not equal.\n\nThe use of files_are_equal is crucial in maintaining data integrity when files are fetched from different sources. By ensuring that the contents of the files match, it helps prevent issues that may arise from discrepancies in the data.\n\n**Note**: When using the files_are_equal function, it is important to ensure that the file paths provided are correct and that the files are accessible. The function assumes that the files can be opened without any permission issues. Additionally, the function handles files in both binary and text modes, which is essential for accurately comparing different types of files.\n\n**Output Example**: If the two files being compared are identical, the function will return:\n```\nTrue\n```\nIf the files differ, the function will log a warning and return:\n```\nFalse\n```"
      ],
      "code_start_line": 247,
      "code_end_line": 264,
      "params": [
        "filename1",
        "filename2"
      ],
      "have_return": true,
      "code_content": "def files_are_equal(filename1, filename2):\n    with open(filename1, 'rb') as file1:\n        contents1 = file1.read()\n    with open(filename2, 'rb') as file2:\n        contents2 = file2.read()\n    eq = contents1 == contents2\n\n    if not eq:\n        with open(filename1, 'r', encoding='utf-8') as f1, \\\n                open(filename2, 'r', encoding='utf-8') as f2:\n            f1lines = f1.readlines()\n            f2lines = f2.readlines()\n\n            diff = indent(\n                ''.join(difflib.unified_diff(f1lines, f2lines)))\n            log.warning(f\"found diff in files ({filename1}, {filename2}):\\n{diff}\\n\")\n\n    return eq\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "dataset/verify.py/get_files_from_hosts_and_compare"
      ],
      "reference_who": [
        "dataset/verify.py/indent"
      ],
      "special_reference_type": [
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "get_files_from_hosts_and_compare",
      "md_content": [
        "**get_files_from_hosts_and_compare**: The function of get_files_from_hosts_and_compare is to retrieve the same file from multiple hosts and ensure that they have identical contents.\n\n**parameters**: The parameters of this Function.\n· hosts: A list of strings representing the host addresses from which the file will be downloaded. The first host is treated as the primary host.\n· path: A string representing the path to the file on the remote hosts.\n· filename: A string representing the name of the file to be saved locally.\n· require_all: A boolean indicating whether all hosts must successfully provide the file for the operation to be considered successful. Defaults to False.\n\n**Code Description**: The get_files_from_hosts_and_compare function is designed to facilitate the retrieval of a specified file from multiple remote hosts and to verify that the contents of the downloaded files are identical. The function begins by asserting that more than one host is provided, as it requires at least one primary host and one or more additional hosts for comparison.\n\nThe primary host is defined as the first entry in the hosts list, and the function constructs a URL for the file to be downloaded from this host. It utilizes the download_with_wget function to attempt to download the file. If the download from the primary host fails, an error is logged, and the function returns a specific ReturnCode indicating the failure.\n\nSubsequently, the function iterates over the remaining hosts, downloading the same file from each. If the require_all parameter is set to True and any of the additional hosts fail to provide the file, the function logs an error and returns a ReturnCode indicating that a file is missing from one host. If a host fails to provide the file but require_all is False, a warning is logged, and the function continues with the files obtained from the primary host.\n\nOnce all files have been downloaded, the function compares the contents of the downloaded files using the files_are_equal function. If any pair of files is found to be different, an error is logged, and the function returns a ReturnCode indicating that the files are not equal. If all files are confirmed to be identical, the function returns a ReturnCode indicating success.\n\nThis function is called by the verify_published_handler function, which is responsible for orchestrating the verification of published binaries. In this context, get_files_from_hosts_and_compare is used to retrieve and compare signature files and checksum files from multiple hosts, ensuring that the verification process is based on consistent and reliable data.\n\n**Note**: When using the get_files_from_hosts_and_compare function, it is essential to ensure that the provided hosts are valid and reachable. Additionally, the path and filename parameters must be correctly specified to avoid download failures. The function assumes that the files can be accessed without permission issues on the remote hosts.\n\n**Output Example**: A possible return value of the function could be ReturnCode.SUCCESS, indicating that all files were successfully retrieved and verified as identical. If there was a failure in downloading from the primary host, the return value could be ReturnCode.FILE_GET_FAILED."
      ],
      "code_start_line": 267,
      "code_end_line": 326,
      "params": [
        "hosts",
        "path",
        "filename",
        "require_all"
      ],
      "have_return": true,
      "code_content": "def get_files_from_hosts_and_compare(\n    hosts: t.List[str], path: str, filename: str, require_all: bool = False\n) -> ReturnCode:\n    \"\"\"\n    Retrieve the same file from a number of hosts and ensure they have the same contents.\n    The first host given will be treated as the \"primary\" host, and is required to succeed.\n\n    Args:\n        filename: for writing the file locally.\n    \"\"\"\n    assert len(hosts) > 1\n    primary_host = hosts[0]\n    other_hosts = hosts[1:]\n    got_files = []\n\n    def join_url(host: str) -> str:\n        return host.rstrip('/') + '/' + path.lstrip('/')\n\n    url = join_url(primary_host)\n    success, output = download_with_wget(url, filename)\n    if not success:\n        log.error(\n            f\"couldn't fetch file ({url}). \"\n            \"Have you specified the version number in the following format?\\n\"\n            f\"{VERSION_FORMAT} \"\n            f\"(example: {VERSION_EXAMPLE})\\n\"\n            f\"wget output:\\n{indent(output)}\")\n        return ReturnCode.FILE_GET_FAILED\n    else:\n        log.info(f\"got file {url} as {filename}\")\n        got_files.append(filename)\n\n    for i, host in enumerate(other_hosts):\n        url = join_url(host)\n        fname = filename + f'.{i + 2}'\n        success, output = download_with_wget(url, fname)\n\n        if require_all and not success:\n            log.error(\n                f\"{host} failed to provide file ({url}), but {primary_host} did?\\n\"\n                f\"wget output:\\n{indent(output)}\")\n            return ReturnCode.FILE_MISSING_FROM_ONE_HOST\n        elif not success:\n            log.warning(\n                f\"{host} failed to provide file ({url}). \"\n                f\"Continuing based solely upon {primary_host}.\")\n        else:\n            log.info(f\"got file {url} as {fname}\")\n            got_files.append(fname)\n\n    for i, got_file in enumerate(got_files):\n        if got_file == got_files[-1]:\n            break  # break on last file, nothing after it to compare to\n\n        compare_to = got_files[i + 1]\n        if not files_are_equal(got_file, compare_to):\n            log.error(f\"files not equal: {got_file} and {compare_to}\")\n            return ReturnCode.FILES_NOT_EQUAL\n\n    return ReturnCode.SUCCESS\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "dataset/verify.py/verify_published_handler"
      ],
      "reference_who": [
        "dataset/verify.py/ReturnCode",
        "dataset/verify.py/indent",
        "dataset/verify.py/download_with_wget",
        "dataset/verify.py/files_are_equal"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "join_url",
      "md_content": [
        "**join_url**: The function of join_url is to concatenate a host URL with a specified path, ensuring proper formatting by removing any trailing slashes from the host and leading slashes from the path.\n\n**parameters**: The parameters of this Function.\n· host: A string representing the base URL or host to which the path will be appended.\n\n**Code Description**: The join_url function takes a single parameter, host, which is expected to be a string. The function performs two main operations to ensure that the resulting URL is correctly formatted. First, it uses the rstrip('/') method on the host string to remove any trailing slashes. This is important because having a trailing slash can lead to double slashes when concatenating with the path. Next, it concatenates the cleaned host with a forward slash ('/') and the path, which is processed using lstrip('/') to remove any leading slashes. This ensures that the path does not start with a slash, preventing the formation of an incorrect URL structure. The final result is a well-formed URL that combines the host and the path.\n\n**Note**: It is essential to ensure that the host parameter is a valid URL format. Additionally, the path variable should be defined in the scope where the join_url function is called, as it is not passed as a parameter. Users should be cautious about the input values to avoid unexpected URL formats.\n\n**Output Example**: If the host is \"http://example.com/\" and the path is \"/api/v1/resource\", the function will return \"http://example.com/api/v1/resource\"."
      ],
      "code_start_line": 282,
      "code_end_line": 283,
      "params": [
        "host"
      ],
      "have_return": true,
      "code_content": "    def join_url(host: str) -> str:\n        return host.rstrip('/') + '/' + path.lstrip('/')\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "check_multisig",
      "md_content": [
        "**check_multisig**: The function of check_multisig is to verify the signatures of a specified sums file against a provided GPG signature file and return the results of the verification process.\n\n**parameters**: The parameters of this Function.\n· sums_file: A string representing the path to the file containing the checksums that need to be verified.\n· sigfilename: A string representing the path to the GPG signature file associated with the sums file.\n· args: An instance of argparse.Namespace containing command-line arguments that influence the behavior of the function.\n\n**Code Description**: The check_multisig function is responsible for verifying the authenticity of signatures associated with a sums file using GPG (GNU Privacy Guard). The function begins by calling the verify_with_gpg function, which executes the GPG command to check the signatures and returns a status code along with the output from GPG. The output is then processed to categorize the signatures into three lists: good, unknown, and bad, using the parse_gpg_result function.\n\nIf there are any unknown signatures and the user has specified the option to import keys, the function prompts the user for confirmation to retrieve the unknown keys from a keyserver. If the user agrees, it attempts to retrieve the keys using a subprocess call to GPG. After retrieving the keys, the function re-verifies the signatures by calling verify_with_gpg again and updates the lists of good, unknown, and bad signatures.\n\nThe function returns a tuple containing the GPG return code, the output from GPG, and the categorized lists of good, unknown, and bad signatures. This structured output allows the calling function, such as verify_shasums_signature, to make informed decisions based on the verification results. In verify_shasums_signature, the results from check_multisig are used to determine if there are enough trusted signatures to meet a specified threshold, logging appropriate messages based on the verification outcome.\n\n**Note**: It is essential to ensure that the GPG environment is properly set up and that the necessary keys are accessible for the verification process to succeed. Additionally, the function assumes that the input files are correctly formatted and accessible.\n\n**Output Example**: A possible return value from the function could be:\n(0, \"gpg: Good signature from 'John Doe <john@example.com>'\", \n [SigData('A1B2C3D4', 'John Doe', trusted=True, status='')], \n [SigData('E5F6G7H8', 'Unknown Entity', trusted=False, status='')], \n [SigData('I9J0K1L2', 'Malicious Entity', trusted=False, status='revoked')])"
      ],
      "code_start_line": 329,
      "code_end_line": 356,
      "params": [
        "sums_file",
        "sigfilename",
        "args"
      ],
      "have_return": true,
      "code_content": "def check_multisig(sums_file: str, sigfilename: str, args: argparse.Namespace) -> t.Tuple[int, str, t.List[SigData], t.List[SigData], t.List[SigData]]:\n    # check signature\n    #\n    # We don't write output to a file because this command will almost certainly\n    # fail with GPG exit code '2' (and so not writing to --output) because of the\n    # likely presence of multiple untrusted signatures.\n    retval, output = verify_with_gpg(sums_file, sigfilename)\n\n    if args.verbose:\n        log.info(f\"gpg output:\\n{indent(output)}\")\n\n    good, unknown, bad = parse_gpg_result(output.splitlines())\n\n    if unknown and args.import_keys:\n        # Retrieve unknown keys and then try GPG again.\n        for unsig in unknown:\n            if prompt_yn(f\" ? Retrieve key {unsig.key} ({unsig.name})? (y/N) \"):\n                ran = subprocess.run(\n                    [\"gpg\", \"--keyserver\", args.keyserver, \"--recv-keys\", unsig.key])\n\n                if ran.returncode != 0:\n                    log.warning(f\"failed to retrieve key {unsig.key}\")\n\n        # Reparse the GPG output now that we have more keys\n        retval, output = verify_with_gpg(sums_file, sigfilename)\n        good, unknown, bad = parse_gpg_result(output.splitlines())\n\n    return retval, output, good, unknown, bad\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "dataset/verify.py/verify_shasums_signature"
      ],
      "reference_who": [
        "dataset/verify.py/indent",
        "dataset/verify.py/verify_with_gpg",
        "dataset/verify.py/SigData",
        "dataset/verify.py/parse_gpg_result",
        "dataset/verify.py/prompt_yn"
      ],
      "special_reference_type": [
        false,
        false,
        true,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "prompt_yn",
      "md_content": [
        "**prompt_yn**: The function of prompt_yn is to prompt the user for a yes or no input and return a boolean value based on the user's response.\n\n**parameters**: The parameters of this Function.\n· prompt: A string that represents the message displayed to the user when asking for input.\n\n**Code Description**: The prompt_yn function is designed to solicit a yes ('y') or no ('n') response from the user. It begins by initializing a variable `got` to an empty string. The function then enters a while loop that continues until the user provides a valid input, which must be either 'y' or 'n'. Inside the loop, the function calls the input function with the provided prompt, converting the user's response to lowercase to ensure case insensitivity. Once a valid response is received, the function returns True if the response is 'y' and False if it is 'n'.\n\nThis function is utilized within the check_multisig function, which is responsible for verifying signatures associated with a file. Specifically, prompt_yn is called when the program encounters an unknown key during the verification process and the user has opted to import keys. The function prompts the user to confirm whether they wish to retrieve the unknown key from a keyserver. The boolean result from prompt_yn determines whether the program will attempt to retrieve the key using a subprocess call to GPG. This interaction illustrates how prompt_yn facilitates user decision-making in the signature verification workflow.\n\n**Note**: It is important to ensure that the prompt provided to the user is clear and concise, as this will directly affect the user's ability to respond correctly. Additionally, the function only accepts 'y' or 'n' as valid inputs, and any other input will result in the prompt being displayed again.\n\n**Output Example**: If the user inputs 'y', the function will return True. If the user inputs 'n', the function will return False. For any other input, the prompt will be displayed again until a valid response is received."
      ],
      "code_start_line": 359,
      "code_end_line": 364,
      "params": [
        "prompt"
      ],
      "have_return": true,
      "code_content": "def prompt_yn(prompt) -> bool:\n    \"\"\"Return true if the user inputs 'y'.\"\"\"\n    got = ''\n    while got not in ['y', 'n']:\n        got = input(prompt).lower()\n    return got == 'y'\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "dataset/verify.py/check_multisig"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "verify_shasums_signature",
      "md_content": [
        "**verify_shasums_signature**: The function of verify_shasums_signature is to verify the signatures of a SHA256SUMS file against a provided GPG signature file and ensure that the number of trusted signatures meets a specified threshold.\n\n**parameters**: The parameters of this Function.\n· signature_file_path: A string representing the path to the GPG signature file associated with the SHA256SUMS file.  \n· sums_file_path: A string representing the path to the file containing the checksums that need to be verified.  \n· args: An instance of argparse.Namespace containing command-line arguments that influence the behavior of the function, including the minimum number of good signatures required for verification.\n\n**Code Description**: The verify_shasums_signature function is responsible for validating the integrity of a SHA256SUMS file by checking its signatures using GPG (GNU Privacy Guard). It begins by defining the minimum number of good signatures required and the allowed GPG return codes for successful verification. The function then calls check_multisig, which executes the GPG command to verify the signatures and returns a status code along with categorized lists of good, unknown, and bad signatures.\n\nUpon receiving the results from check_multisig, the function checks the GPG return code against the allowed codes. If the return code indicates an integrity failure or an unexpected error, it logs the appropriate error messages and returns a corresponding ReturnCode indicating the failure.\n\nThe function then assesses which signatures are trusted based on the command-line arguments provided. It tallies the good signatures, distinguishing between trusted and untrusted signatures. If the number of trusted signatures is below the specified threshold, it logs a warning and returns a ReturnCode indicating that there are not enough good signatures.\n\nFor each signature, the function logs its status, including good signatures, expired keys, bad signatures, and unknown signatures. Finally, it returns a tuple containing the overall status of the verification process, along with lists of trusted good signatures, untrusted good signatures, unknown signatures, and bad signatures.\n\nThis function is called by other functions such as verify_published_handler and verify_binaries_handler, which handle the overall verification process for published binaries and specific binary files, respectively. These calling functions rely on verify_shasums_signature to ensure that the SHA256SUMS file is properly verified before proceeding with further operations, such as downloading binaries or verifying their hashes.\n\n**Note**: When using the verify_shasums_signature function, it is essential to ensure that the GPG environment is correctly configured and that the necessary keys are available for the verification process to succeed. Additionally, the function assumes that the input files are correctly formatted and accessible.\n\n**Output Example**: A possible return value from the function could be:\n(ReturnCode.SUCCESS, \n [SigData('A1B2C3D4', 'John Doe', trusted=True, status='')], \n [SigData('E5F6G7H8', 'Unknown Entity', trusted=False, status='')], \n [SigData('I9J0K1L2', 'Malicious Entity', trusted=False, status='revoked')])"
      ],
      "code_start_line": 366,
      "code_end_line": 429,
      "params": [
        "signature_file_path",
        "sums_file_path",
        "args"
      ],
      "have_return": true,
      "code_content": "def verify_shasums_signature(\n    signature_file_path: str, sums_file_path: str, args: argparse.Namespace\n) -> t.Tuple[\n   ReturnCode, t.List[SigData], t.List[SigData], t.List[SigData], t.List[SigData]\n]:\n    min_good_sigs = args.min_good_sigs\n    gpg_allowed_codes = [0, 2]  # 2 is returned when untrusted signatures are present.\n\n    gpg_retval, gpg_output, good, unknown, bad = check_multisig(sums_file_path, signature_file_path, args)\n\n    if gpg_retval not in gpg_allowed_codes:\n        if gpg_retval == 1:\n            log.critical(f\"Bad signature (code: {gpg_retval}).\")\n        else:\n            log.critical(f\"unexpected GPG exit code ({gpg_retval})\")\n\n        log.error(f\"gpg output:\\n{indent(gpg_output)}\")\n        return (ReturnCode.INTEGRITY_FAILURE, [], [], [], [])\n\n    # Decide which keys we trust, though not \"trust\" in the GPG sense, but rather\n    # which pubkeys convince us that this sums file is legitimate. In other words,\n    # which pubkeys within the Bitcoin community do we trust for the purposes of\n    # binary verification?\n    trusted_keys = set()\n    if args.trusted_keys:\n        trusted_keys |= set(args.trusted_keys.split(','))\n\n    # Tally signatures and make sure we have enough goods to fulfill\n    # our threshold.\n    good_trusted = [sig for sig in good if sig.trusted or sig.key in trusted_keys]\n    good_untrusted = [sig for sig in good if sig not in good_trusted]\n    num_trusted = len(good_trusted) + len(good_untrusted)\n    log.info(f\"got {num_trusted} good signatures\")\n\n    if num_trusted < min_good_sigs:\n        log.info(\"Maybe you need to import \"\n                  f\"(`gpg --keyserver {args.keyserver} --recv-keys <key-id>`) \"\n                  \"some of the following keys: \")\n        log.info('')\n        for sig in unknown:\n            log.info(f\"    {sig.key} ({sig.name})\")\n        log.info('')\n        log.error(\n            \"not enough trusted sigs to meet threshold \"\n            f\"({num_trusted} vs. {min_good_sigs})\")\n\n        return (ReturnCode.NOT_ENOUGH_GOOD_SIGS, [], [], [], [])\n\n    for sig in good_trusted:\n        log.info(f\"GOOD SIGNATURE: {sig}\")\n\n    for sig in good_untrusted:\n        log.info(f\"GOOD SIGNATURE (untrusted): {sig}\")\n\n    for sig in [sig for sig in good if sig.status == 'expired']:\n        log.warning(f\"key {sig.key} for {sig.name} is expired\")\n\n    for sig in bad:\n        log.warning(f\"BAD SIGNATURE: {sig}\")\n\n    for sig in unknown:\n        log.warning(f\"UNKNOWN SIGNATURE: {sig}\")\n\n    return (ReturnCode.SUCCESS, good_trusted, good_untrusted, unknown, bad)\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "dataset/verify.py/verify_published_handler",
        "dataset/verify.py/verify_binaries_handler"
      ],
      "reference_who": [
        "dataset/verify.py/ReturnCode",
        "dataset/verify.py/indent",
        "dataset/verify.py/SigData",
        "dataset/verify.py/check_multisig"
      ],
      "special_reference_type": [
        false,
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "parse_sums_file",
      "md_content": [
        "**parse_sums_file**: The function of parse_sums_file is to extract hashes and filenames of binaries to verify from a specified hash file.\n\n**parameters**: The parameters of this Function.\n· sums_file_path: A string representing the path to the hash file that contains the hashes and binary filenames.\n· filename_filter: A list of strings used to filter the filenames extracted from the hash file. If empty, all entries will be returned.\n\n**Code Description**: The parse_sums_file function reads a hash file specified by the sums_file_path parameter. Each line in this file is expected to contain a hash followed by a binary filename, formatted as \"<hash> <binary_filename>\". The function processes the file line by line, splitting each line into its constituent parts. It checks if the filename_filter is empty or if any of the filters are present in the line. If either condition is met, the hash and filename are included in the returned list. The function ultimately returns a list of lists, where each inner list contains a hash and its corresponding binary filename.\n\nThis function is called by two different handlers within the dataset/verify.py module: verify_published_handler and verify_binaries_handler. In verify_published_handler, it is used to extract hashes and filenames after verifying the signature of the SHA256SUMS file. The extracted data is then filtered to remove binaries that are not hosted by the specified source. In verify_binaries_handler, parse_sums_file is utilized to extract hashes and filenames from a user-specified sums file, which are then verified against the provided binaries. Both handlers rely on the output of parse_sums_file to ensure that the correct binaries are being processed for verification.\n\n**Note**: It is important to ensure that the sums_file_path provided points to a valid file with the expected format. If the filename_filter is not used, the function will return all entries from the hash file, which may include unwanted binaries.\n\n**Output Example**: An example of the return value from parse_sums_file could be:\n```\n[\n    ['abc123hash', 'binary_file_1'],\n    ['def456hash', 'binary_file_2']\n]\n``` \nThis output indicates that two binaries, 'binary_file_1' and 'binary_file_2', have been extracted along with their corresponding hashes from the specified hash file."
      ],
      "code_start_line": 432,
      "code_end_line": 436,
      "params": [
        "sums_file_path",
        "filename_filter"
      ],
      "have_return": true,
      "code_content": "def parse_sums_file(sums_file_path: str, filename_filter: t.List[str]) -> t.List[t.List[str]]:\n    # extract hashes/filenames of binaries to verify from hash file;\n    # each line has the following format: \"<hash> <binary_filename>\"\n    with open(sums_file_path, 'r', encoding='utf8') as hash_file:\n        return [line.split()[:2] for line in hash_file if len(filename_filter) == 0 or any(f in line for f in filename_filter)]\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "dataset/verify.py/verify_published_handler",
        "dataset/verify.py/verify_binaries_handler"
      ],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "verify_binary_hashes",
      "md_content": [
        "**verify_binary_hashes**: The function of verify_binary_hashes is to verify the integrity of binary files by comparing their calculated SHA256 hashes against expected values.\n\n**parameters**: The parameters of this Function.\n· hashes_to_verify: A list of lists, where each inner list contains an expected hash and the corresponding binary filename to verify.\n\n**Code Description**: The verify_binary_hashes function is designed to ensure the integrity of binary files by calculating their SHA256 hashes and comparing them to expected values provided in the hashes_to_verify parameter. The function begins by initializing two lists: offending_files, which will store the names of files that fail the hash check, and files_to_hashes, which will map binary filenames to their calculated hashes.\n\nThe function iterates over each pair of expected hash and binary filename from the hashes_to_verify list. For each binary file, it opens the file in binary read mode and computes its SHA256 hash using the sha256 function. If the calculated hash does not match the expected hash, the filename is added to the offending_files list. If the hashes match, the filename and its calculated hash are stored in the files_to_hashes dictionary.\n\nAfter processing all files, if there are any offending files, the function logs a critical error message detailing which files failed the integrity check and returns a tuple containing ReturnCode.INTEGRITY_FAILURE and the files_to_hashes dictionary. If all files pass the integrity check, the function returns a tuple with ReturnCode.SUCCESS and the files_to_hashes dictionary.\n\nThis function is called by verify_published_handler and verify_binaries_handler functions within the same module. In verify_published_handler, it is invoked after downloading binaries and verifying their signatures, ensuring that the downloaded files are intact and have not been tampered with. In verify_binaries_handler, it is called after verifying the signature of the SHA256SUMS file and extracting the hashes to verify, ensuring that the specified binaries match their expected hashes.\n\n**Note**: It is important to handle the return values of this function appropriately in the calling functions to ensure that any integrity failures are logged and managed correctly. This practice is crucial for maintaining the robustness of the verification process.\n\n**Output Example**: A possible return value of the function could be:\n- If all hashes match: (ReturnCode.SUCCESS, {'binary1': 'calculated_hash1', 'binary2': 'calculated_hash2'})\n- If there are integrity failures: (ReturnCode.INTEGRITY_FAILURE, {'binary1': 'calculated_hash1'})"
      ],
      "code_start_line": 439,
      "code_end_line": 458,
      "params": [
        "hashes_to_verify"
      ],
      "have_return": true,
      "code_content": "def verify_binary_hashes(hashes_to_verify: t.List[t.List[str]]) -> t.Tuple[ReturnCode, t.Dict[str, str]]:\n    offending_files = []\n    files_to_hashes = {}\n\n    for hash_expected, binary_filename in hashes_to_verify:\n        with open(binary_filename, 'rb') as binary_file:\n            hash_calculated = sha256(binary_file.read()).hexdigest()\n        if hash_calculated != hash_expected:\n            offending_files.append(binary_filename)\n        else:\n            files_to_hashes[binary_filename] = hash_calculated\n\n    if offending_files:\n        joined_files = '\\n'.join(offending_files)\n        log.critical(\n            \"Hashes don't match.\\n\"\n            f\"Offending files:\\n{joined_files}\")\n        return (ReturnCode.INTEGRITY_FAILURE, files_to_hashes)\n\n    return (ReturnCode.SUCCESS, files_to_hashes)\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "dataset/verify.py/verify_published_handler",
        "dataset/verify.py/verify_binaries_handler"
      ],
      "reference_who": [
        "dataset/verify.py/ReturnCode"
      ],
      "special_reference_type": [
        true
      ]
    },
    {
      "type": "FunctionDef",
      "name": "verify_published_handler",
      "md_content": [
        "**verify_published_handler**: The function of verify_published_handler is to verify the integrity and authenticity of published Bitcoin binaries based on a specified version.\n\n**parameters**: The parameters of this Function.\n· args: An instance of argparse.Namespace that contains command-line arguments, including the version of the Bitcoin release to verify, cleanup options, and host requirements for signature verification.\n\n**Code Description**: The verify_published_handler function orchestrates the process of verifying published Bitcoin binaries by performing several key operations. It begins by establishing a working directory in the system's temporary directory, specifically named according to the version provided in the arguments.\n\nThe function first attempts to parse the version string using the parse_version_string function, which extracts the base version, release candidate (if applicable), and operating system information. If parsing fails, it logs an error and returns a ReturnCode indicating a bad version.\n\nNext, the function constructs the remote directory path for the binaries and their associated signatures based on the parsed version information. It then creates the working directory and changes the current working directory to this new location.\n\nThe function retrieves signature files from specified hosts using the get_files_from_hosts_and_compare function, which ensures that the signatures are identical across the hosts. If the retrieval is unsuccessful, it returns the corresponding error code.\n\nFollowing this, the function checks if the version is suitable for multi-signature verification. If the version is below 22.0, it logs an error indicating that single signature verification is not supported and returns a bad version code.\n\nThe function then retrieves checksum files in a similar manner and verifies the integrity of the SHA256SUMS file against its signature using the verify_shasums_signature function. If this verification fails, it cleans up the working directory if necessary and returns the appropriate error code.\n\nOnce the signatures and checksums are verified, the function extracts the hashes and filenames of the binaries to be verified using the parse_sums_file function. It filters out any binaries that are not hosted by the specified source.\n\nThe function proceeds to download the binaries using the download_with_wget function, logging the status of each download. If any downloads fail, it returns an error code indicating the failure.\n\nFinally, the function verifies the integrity of the downloaded binaries by comparing their hashes against the expected values using the verify_binary_hashes function. If all checks pass, it outputs the results, either in JSON format or as a simple list of verified binaries, and returns a success code.\n\nThis function is called by the main function of the module, which sets up the command-line interface for the script. The main function defines a subcommand \"pub\" that links directly to verify_published_handler, allowing users to invoke this verification process through command-line arguments.\n\n**Note**: It is essential to ensure that the version string provided adheres to the expected format, and that the necessary network access is available to retrieve files from the specified hosts. Additionally, users should be aware of the cleanup option, which determines whether temporary files are removed after the verification process.\n\n**Output Example**: A possible return value of the function could be ReturnCode.SUCCESS, indicating that all binaries have been successfully verified, along with a printed list of verified binaries or a JSON output containing detailed verification results."
      ],
      "code_start_line": 461,
      "code_end_line": 567,
      "params": [
        "args"
      ],
      "have_return": true,
      "code_content": "def verify_published_handler(args: argparse.Namespace) -> ReturnCode:\n    WORKINGDIR = Path(tempfile.gettempdir()) / f\"bitcoin_verify_binaries.{args.version}\"\n\n    def cleanup():\n        log.info(\"cleaning up files\")\n        os.chdir(Path.home())\n        shutil.rmtree(WORKINGDIR)\n\n    # determine remote dir dependent on provided version string\n    try:\n        version_base, version_rc, os_filter = parse_version_string(args.version)\n        version_tuple = [int(i) for i in version_base.split('.')]\n    except Exception as e:\n        log.debug(e)\n        log.error(f\"unable to parse version; expected format is {VERSION_FORMAT}\")\n        log.error(f\"  e.g. {VERSION_EXAMPLE}\")\n        return ReturnCode.BAD_VERSION\n\n    remote_dir = f\"/bin/{VERSIONPREFIX}{version_base}/\"\n    if version_rc:\n        remote_dir += f\"test.{version_rc}/\"\n    remote_sigs_path = remote_dir + SIGNATUREFILENAME\n    remote_sums_path = remote_dir + SUMS_FILENAME\n\n    # create working directory\n    os.makedirs(WORKINGDIR, exist_ok=True)\n    os.chdir(WORKINGDIR)\n\n    hosts = [HOST1, HOST2]\n\n    got_sig_status = get_files_from_hosts_and_compare(\n        hosts, remote_sigs_path, SIGNATUREFILENAME, args.require_all_hosts)\n    if got_sig_status != ReturnCode.SUCCESS:\n        return got_sig_status\n\n    # Multi-sig verification is available after 22.0.\n    if version_tuple[0] < 22:\n        log.error(\"Version too old - single sig not supported. Use a previous \"\n                  \"version of this script from the repo.\")\n        return ReturnCode.BAD_VERSION\n\n    got_sums_status = get_files_from_hosts_and_compare(\n        hosts, remote_sums_path, SUMS_FILENAME, args.require_all_hosts)\n    if got_sums_status != ReturnCode.SUCCESS:\n        return got_sums_status\n\n    # Verify the signature on the SHA256SUMS file\n    sigs_status, good_trusted, good_untrusted, unknown, bad = verify_shasums_signature(SIGNATUREFILENAME, SUMS_FILENAME, args)\n    if sigs_status != ReturnCode.SUCCESS:\n        if sigs_status == ReturnCode.INTEGRITY_FAILURE:\n            cleanup()\n        return sigs_status\n\n    # Extract hashes and filenames\n    hashes_to_verify = parse_sums_file(SUMS_FILENAME, [os_filter])\n    if not hashes_to_verify:\n        log.error(\"no files matched the platform specified\")\n        return ReturnCode.NO_BINARIES_MATCH\n\n    # remove binaries that are known not to be hosted by bitcoincore.org\n    fragments_to_remove = ['-unsigned', '-debug', '-codesignatures']\n    for fragment in fragments_to_remove:\n        nobinaries = [i for i in hashes_to_verify if fragment in i[1]]\n        if nobinaries:\n            remove_str = ', '.join(i[1] for i in nobinaries)\n            log.info(\n                f\"removing *{fragment} binaries ({remove_str}) from verification \"\n                f\"since {HOST1} does not host *{fragment} binaries\")\n            hashes_to_verify = [i for i in hashes_to_verify if fragment not in i[1]]\n\n    # download binaries\n    for _, binary_filename in hashes_to_verify:\n        log.info(f\"downloading {binary_filename} to {WORKINGDIR}\")\n        success, output = download_with_wget(\n            HOST1 + remote_dir + binary_filename, binary_filename)\n\n        if not success:\n            log.error(\n                f\"failed to download {binary_filename}\\n\"\n                f\"wget output:\\n{indent(output)}\")\n            return ReturnCode.BINARY_DOWNLOAD_FAILED\n\n    # verify hashes\n    hashes_status, files_to_hashes = verify_binary_hashes(hashes_to_verify)\n    if hashes_status != ReturnCode.SUCCESS:\n        return hashes_status\n\n\n    if args.cleanup:\n        cleanup()\n    else:\n        log.info(f\"did not clean up {WORKINGDIR}\")\n\n    if args.json:\n        output = {\n            'good_trusted_sigs': [str(s) for s in good_trusted],\n            'good_untrusted_sigs': [str(s) for s in good_untrusted],\n            'unknown_sigs': [str(s) for s in unknown],\n            'bad_sigs': [str(s) for s in bad],\n            'verified_binaries': files_to_hashes,\n        }\n        print(json.dumps(output, indent=2))\n    else:\n        for filename in files_to_hashes:\n            print(f\"VERIFIED: {filename}\")\n\n    return ReturnCode.SUCCESS\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "dataset/verify.py/main"
      ],
      "reference_who": [
        "dataset/verify.py/ReturnCode",
        "dataset/verify.py/indent",
        "dataset/verify.py/parse_version_string",
        "dataset/verify.py/download_with_wget",
        "dataset/verify.py/get_files_from_hosts_and_compare",
        "dataset/verify.py/verify_shasums_signature",
        "dataset/verify.py/parse_sums_file",
        "dataset/verify.py/verify_binary_hashes"
      ],
      "special_reference_type": [
        true,
        false,
        false,
        false,
        false,
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "cleanup",
      "md_content": [
        "**cleanup**: The function of cleanup is to remove temporary files and reset the working directory.\n\n**parameters**: The parameters of this Function.\n· There are no parameters for this function.\n\n**Code Description**: The cleanup function is designed to perform a cleanup operation by removing temporary files and resetting the working environment. The function begins by logging an informational message indicating that the cleanup process is starting. This is done using the `log.info` method, which helps in tracking the execution flow and debugging if necessary.\n\nNext, the function changes the current working directory to the user's home directory using `os.chdir(Path.home())`. This step is crucial as it ensures that any subsequent file operations are performed in a known and safe location, preventing accidental modifications to files in other directories.\n\nFinally, the function deletes the directory specified by the `WORKINGDIR` variable and all its contents using `shutil.rmtree(WORKINGDIR)`. This method is powerful as it recursively removes a directory and all its files and subdirectories, effectively cleaning up any temporary files that may have been created during the execution of the program.\n\n**Note**: It is important to ensure that the `WORKINGDIR` variable is correctly defined and points to the intended directory before calling this function. Additionally, users should be cautious when using `shutil.rmtree` as it permanently deletes files and directories without recovery options."
      ],
      "code_start_line": 464,
      "code_end_line": 467,
      "params": [],
      "have_return": false,
      "code_content": "    def cleanup():\n        log.info(\"cleaning up files\")\n        os.chdir(Path.home())\n        shutil.rmtree(WORKINGDIR)\n",
      "name_column": 8,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [],
      "special_reference_type": []
    },
    {
      "type": "FunctionDef",
      "name": "verify_binaries_handler",
      "md_content": [
        "**verify_binaries_handler**: The function of verify_binaries_handler is to verify the integrity and authenticity of specified binary files against a SHA256SUMS file and its associated GPG signature.\n\n**parameters**: The parameters of this Function.\n· args: An instance of argparse.Namespace containing command-line arguments that influence the behavior of the function, including paths to binary files, SHA256SUMS file, and signature file.\n\n**Code Description**: The verify_binaries_handler function is designed to handle the verification process of binary files by checking their signatures and hashes against a provided SHA256SUMS file. The function begins by creating a mapping of binary file names to their respective paths based on the input arguments. If a signature file is specified, it uses that; otherwise, it defaults to assuming the signature file is the SHA256SUMS file with an \".asc\" suffix.\n\nThe function then calls verify_shasums_signature to validate the signature of the SHA256SUMS file. If the signature verification fails, the function returns the corresponding ReturnCode. Following successful signature verification, it extracts the hashes and filenames from the SHA256SUMS file using the parse_sums_file function. If no matching hashes are found for the specified binaries, it logs an error and returns a ReturnCode indicating that no binaries match.\n\nNext, the function ensures that all specified binaries are accounted for by comparing the extracted hashes with the provided binaries. If any binaries are missing, it logs an error. The function then proceeds to verify the integrity of the binaries by calling verify_binary_hashes, which checks the calculated SHA256 hashes against the expected values. If any integrity checks fail, it returns the appropriate ReturnCode.\n\nDepending on the command-line arguments, the function outputs the results in either a human-readable format or as JSON. It concludes by returning ReturnCode.SUCCESS if all operations are successful.\n\nThis function is called by the main function within the same module, specifically when the \"bin\" command is invoked. It serves as a critical component in the verification process, ensuring that the binaries are both authentic and intact before they are used.\n\n**Note**: When using the verify_binaries_handler function, it is essential to provide valid paths for the SHA256SUMS file and the binaries to be verified. Additionally, the GPG environment must be correctly configured for signature verification to succeed.\n\n**Output Example**: A possible return value from the function could be:\nReturnCode.SUCCESS"
      ],
      "code_start_line": 570,
      "code_end_line": 634,
      "params": [
        "args"
      ],
      "have_return": true,
      "code_content": "def verify_binaries_handler(args: argparse.Namespace) -> ReturnCode:\n    binary_to_basename = {}\n    for file in args.binary:\n        binary_to_basename[PurePath(file).name] = file\n\n    sums_sig_path = None\n    if args.sums_sig_file:\n        sums_sig_path = Path(args.sums_sig_file)\n    else:\n        log.info(f\"No signature file specified, assuming it is {args.sums_file}.asc\")\n        sums_sig_path = Path(args.sums_file).with_suffix(\".asc\")\n\n    # Verify the signature on the SHA256SUMS file\n    sigs_status, good_trusted, good_untrusted, unknown, bad = verify_shasums_signature(str(sums_sig_path), args.sums_file, args)\n    if sigs_status != ReturnCode.SUCCESS:\n        return sigs_status\n\n    # Extract hashes and filenames\n    hashes_to_verify = parse_sums_file(args.sums_file, [k for k, n in binary_to_basename.items()])\n    if not hashes_to_verify:\n        log.error(f\"No files in {args.sums_file} match the specified binaries\")\n        return ReturnCode.NO_BINARIES_MATCH\n\n    # Make sure all files are accounted for\n    sums_file_path = Path(args.sums_file)\n    missing_files = []\n    files_to_hash = []\n    if len(binary_to_basename) > 0:\n        for file_hash, file in hashes_to_verify:\n            files_to_hash.append([file_hash, binary_to_basename[file]])\n            del binary_to_basename[file]\n        if len(binary_to_basename) > 0:\n            log.error(f\"Not all specified binaries are in {args.sums_file}\")\n            return ReturnCode.NO_BINARIES_MATCH\n    else:\n        log.info(f\"No binaries specified, assuming all files specified in {args.sums_file} are located relatively\")\n        for file_hash, file in hashes_to_verify:\n            file_path = Path(sums_file_path.parent.joinpath(file))\n            if file_path.exists():\n                files_to_hash.append([file_hash, str(file_path)])\n            else:\n                missing_files.append(file)\n\n    # verify hashes\n    hashes_status, files_to_hashes = verify_binary_hashes(files_to_hash)\n    if hashes_status != ReturnCode.SUCCESS:\n        return hashes_status\n\n    if args.json:\n        output = {\n            'good_trusted_sigs': [str(s) for s in good_trusted],\n            'good_untrusted_sigs': [str(s) for s in good_untrusted],\n            'unknown_sigs': [str(s) for s in unknown],\n            'bad_sigs': [str(s) for s in bad],\n            'verified_binaries': files_to_hashes,\n            \"missing_binaries\": missing_files,\n        }\n        print(json.dumps(output, indent=2))\n    else:\n        for filename in files_to_hashes:\n            print(f\"VERIFIED: {filename}\")\n        for filename in missing_files:\n            print(f\"MISSING: {filename}\")\n\n    return ReturnCode.SUCCESS\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [
        "dataset/verify.py/main"
      ],
      "reference_who": [
        "dataset/verify.py/ReturnCode",
        "dataset/verify.py/verify_shasums_signature",
        "dataset/verify.py/parse_sums_file",
        "dataset/verify.py/verify_binary_hashes"
      ],
      "special_reference_type": [
        true,
        false,
        false,
        false
      ]
    },
    {
      "type": "FunctionDef",
      "name": "main",
      "md_content": [
        "**main**: The function of main is to serve as the entry point for the command-line interface of the verification tool, allowing users to specify various options and commands for verifying Bitcoin binaries and published releases.\n\n**parameters**: The parameters of this Function.\n· None (The function does not take any parameters directly; it utilizes argparse to handle command-line arguments.)\n\n**Code Description**: The main function initializes a command-line interface using the argparse library, which facilitates user interaction with the verification tool. It begins by creating an ArgumentParser instance, which is configured with a description derived from the module's docstring. The function then defines several command-line arguments that users can specify when executing the script.\n\nKey arguments include:\n- `-v` or `--verbose`: Enables verbose output if specified.\n- `-q` or `--quiet`: Suppresses output messages if specified.\n- `--import-keys`: Prompts the user to import unknown builder keys if specified.\n- `--min-good-sigs`: Sets the minimum number of good signatures required for successful verification, defaulting to 3 unless overridden by an environment variable.\n- `--keyserver`: Specifies the keyserver to use for key retrieval, with a default value set to 'hkps://keys.openpgp.org'.\n- `--trusted-keys`: Accepts a comma-separated list of trusted signer GPG keys.\n- `--json`: Outputs the results in JSON format if specified.\n\nThe function also establishes subcommands for the verification process:\n1. `pub`: This subcommand is linked to the `verify_published_handler` function, which handles the verification of published Bitcoin releases based on a specified version.\n2. `bin`: This subcommand is associated with the `verify_binaries_handler` function, which verifies local binary files against a SHA256SUMS file and its signature.\n\nAfter parsing the command-line arguments, the function checks the verbosity level and adjusts the logging settings accordingly. It then invokes the appropriate handler function (either `verify_published_handler` or `verify_binaries_handler`) based on the user's command, passing the parsed arguments to it.\n\nThe main function plays a crucial role in orchestrating the verification process by setting up the necessary configurations and delegating tasks to the respective handler functions. It ensures that users can easily interact with the tool and customize their verification experience through command-line options.\n\n**Note**: Users should ensure that they provide valid command-line arguments and that the necessary environment variables are set for optimal functionality. It is also important to follow the expected formats for version strings and file paths to avoid errors during execution.\n\n**Output Example**: The function does not return a value directly; instead, it triggers the execution of the specified verification process, which may result in output such as verification results printed to the console or in JSON format, depending on the user's command-line options."
      ],
      "code_start_line": 637,
      "code_end_line": 709,
      "params": [],
      "have_return": true,
      "code_content": "def main():\n    parser = argparse.ArgumentParser(description=__doc__)\n    parser.add_argument(\n        '-v', '--verbose', action='store_true',\n        default=bool_from_env('BINVERIFY_VERBOSE'),\n    )\n    parser.add_argument(\n        '-q', '--quiet', action='store_true',\n        default=bool_from_env('BINVERIFY_QUIET'),\n    )\n    parser.add_argument(\n        '--import-keys', action='store_true',\n        default=bool_from_env('BINVERIFY_IMPORTKEYS'),\n        help='if specified, ask to import each unknown builder key'\n    )\n    parser.add_argument(\n        '--min-good-sigs', type=int, action='store', nargs='?',\n        default=int(os.environ.get('BINVERIFY_MIN_GOOD_SIGS', 3)),\n        help=(\n            'The minimum number of good signatures to require successful termination.'),\n    )\n    parser.add_argument(\n        '--keyserver', action='store', nargs='?',\n        default=os.environ.get('BINVERIFY_KEYSERVER', 'hkps://keys.openpgp.org'),\n        help='which keyserver to use',\n    )\n    parser.add_argument(\n        '--trusted-keys', action='store', nargs='?',\n        default=os.environ.get('BINVERIFY_TRUSTED_KEYS', ''),\n        help='A list of trusted signer GPG keys, separated by commas. Not \"trusted keys\" in the GPG sense.',\n    )\n    parser.add_argument(\n        '--json', action='store_true',\n        default=bool_from_env('BINVERIFY_JSON'),\n        help='If set, output the result as JSON',\n    )\n\n    subparsers = parser.add_subparsers(title=\"Commands\", required=True, dest=\"command\")\n\n    pub_parser = subparsers.add_parser(\"pub\", help=\"Verify a published release.\")\n    pub_parser.set_defaults(func=verify_published_handler)\n    pub_parser.add_argument(\n        'version', type=str, help=(\n            f'version of the bitcoin release to download; of the format '\n            f'{VERSION_FORMAT}. Example: {VERSION_EXAMPLE}')\n    )\n    pub_parser.add_argument(\n        '--cleanup', action='store_true',\n        default=bool_from_env('BINVERIFY_CLEANUP'),\n        help='if specified, clean up files afterwards'\n    )\n    pub_parser.add_argument(\n        '--require-all-hosts', action='store_true',\n        default=bool_from_env('BINVERIFY_REQUIRE_ALL_HOSTS'),\n        help=(\n            f'If set, require all hosts ({HOST1}, {HOST2}) to provide signatures. '\n            '(Sometimes bitcoin.org lags behind bitcoincore.org.)')\n    )\n\n    bin_parser = subparsers.add_parser(\"bin\", help=\"Verify local binaries.\")\n    bin_parser.set_defaults(func=verify_binaries_handler)\n    bin_parser.add_argument(\"--sums-sig-file\", \"-s\", help=\"Path to the SHA256SUMS.asc file to verify\")\n    bin_parser.add_argument(\"sums_file\", help=\"Path to the SHA256SUMS file to verify\")\n    bin_parser.add_argument(\n        \"binary\", nargs=\"*\",\n        help=\"Path to a binary distribution file to verify. Can be specified multiple times for multiple files to verify.\"\n    )\n\n    args = parser.parse_args()\n    if args.quiet:\n        log.setLevel(logging.WARNING)\n\n    return args.func(args)\n",
      "name_column": 4,
      "item_status": "doc_up_to_date",
      "who_reference_me": [],
      "reference_who": [
        "dataset/verify.py/bool_from_env",
        "dataset/verify.py/verify_published_handler",
        "dataset/verify.py/verify_binaries_handler"
      ],
      "special_reference_type": [
        false,
        false,
        false
      ]
    }
  ]
}