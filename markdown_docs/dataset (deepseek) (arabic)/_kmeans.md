## FunctionDef kmeans_plusplus(X, n_clusters)
**kmeans_plusplus**: وظيفة `kmeans_plusplus` هي تهيئة البذور الأولية لمراكز التجميع باستخدام خوارزمية k-means++.

**المعلمات**:
· `X`: مصفوفة أو مصفوفة متفرقة (sparse matrix) ذات شكل (n_samples, n_features) تمثل البيانات التي سيتم اختيار البذور منها.
· `n_clusters`: عدد صحيح يمثل عدد المراكز (البذور) التي سيتم تهيئتها.
· `sample_weight`: مصفوفة ذات شكل (n_samples,) تمثل الأوزان لكل ملاحظة في `X`. إذا كانت القيمة `None`، يتم تعيين وزن متساوٍ لجميع الملاحظات.
· `x_squared_norms`: مصفوفة ذات شكل (n_samples,) تمثل القيم التربيعية للأبعاد الإقليدية لكل نقطة بيانات. إذا كانت القيمة `None`، يتم حسابها تلقائيًا.
· `random_state`: عدد صحيح أو كائن من نوع `RandomState` يستخدم لتوليد الأرقام العشوائية لتهيئة المراكز. إذا تم تمرير عدد صحيح، يتم ضمان إعادة إنتاج النتائج عبر استدعاءات متعددة للدالة.
· `n_local_trials`: عدد صحيح اختياري يمثل عدد المحاولات المحلية لاختيار كل مركز (باستثناء المركز الأول). إذا كانت القيمة `None`، يتم تعيين عدد المحاولات بناءً على عدد البذور باستخدام الصيغة `2 + log(k)`.

**وصف الكود**:
تقوم الدالة `kmeans_plusplus` بتهيئة البذور الأولية لمراكز التجميع باستخدام خوارزمية k-means++، وهي طريقة ذكية لاختيار المراكز الأولية التي تسرع من تقارب خوارزمية k-means. تبدأ الدالة بالتحقق من صحة البيانات المدخلة (`X`) باستخدام الدالة `check_array`، ثم تقوم بتحويل أوزان العينات (`sample_weight`) إلى تنسيق مناسب باستخدام الدالة `_check_sample_weight`. إذا لم يتم توفير `x_squared_norms`، يتم حسابها باستخدام الدالة `row_norms`.

بعد ذلك، يتم استدعاء الدالة `_kmeans_plusplus` التي تقوم بالجزء الحسابي لاختيار المراكز الأولية. تبدأ هذه الدالة باختيار المركز الأول بشكل عشوائي من البيانات، ثم تقوم باختيار المراكز المتبقية بناءً على الاحتمالية المتناسبة مع المسافة التربيعية لأقرب مركز موجود. يتم ذلك من خلال إجراء عدد من المحاولات المحلية (`n_local_trials`) لاختيار المراكز التي تقلل من القصور الذاتي (inertia) بشكل أكبر.

تعيد الدالة `kmeans_plusplus` مصفوفتين: الأولى تحتوي على المراكز الأولية للتجميع (`centers`)، والثانية تحتوي على مواقع هذه المراكز في مصفوفة البيانات الأصلية (`indices`).

**ملاحظات**:
- يجب أن يكون عدد العينات في `X` أكبر من أو يساوي عدد المراكز (`n_clusters`)، وإلا سيتم رفع خطأ.
- إذا لم يتم توفير `x_squared_norms`، يتم حسابها تلقائيًا، ولكن يجب أن يتطابق طولها مع عدد العينات في `X`.
- يتم استخدام `random_state` لضمان إعادة إنتاج النتائج عبر استدعاءات متعددة للدالة.

**مثال للإخراج**:
```python
centers = array([[1.5, 2.0],
                 [4.5, 3.0]])
indices = array([0, 5])
```
حيث `centers` هي مصفوفة تحتوي على المراكز الأولية للتجميع، و`indices` هي مصفوفة تحتوي على مواقع هذه المراكز في مصفوفة البيانات الأصلية `X`.
## FunctionDef _kmeans_plusplus(X, n_clusters, x_squared_norms, sample_weight, random_state, n_local_trials)
**_kmeans_plusplus**: وظيفة `_kmeans_plusplus` هي حساب المكونات الأولية لتهيئة مراكز التجميع باستخدام خوارزمية k-means++.

**المعلمات**:
· `X`: مصفوفة أو مصفوفة متفرقة (sparse matrix) ذات شكل (n_samples, n_features) تمثل البيانات التي سيتم اختيار البذور منها.
· `n_clusters`: عدد صحيح يمثل عدد البذور (المراكز) التي سيتم اختيارها.
· `x_squared_norms`: مصفوفة ذات شكل (n_samples,) تمثل القيم التربيعية للأبعاد الإقليدية لكل نقطة بيانات.
· `sample_weight`: مصفوفة ذات شكل (n_samples,) تمثل الأوزان لكل ملاحظة في `X`.
· `random_state`: كائن من نوع `RandomState` يستخدم لتوليد الأرقام العشوائية لتهيئة المراكز.
· `n_local_trials`: عدد صحيح اختياري يمثل عدد المحاولات المحلية لاختيار كل مركز (باستثناء المركز الأول). إذا لم يتم تحديده، يتم تعيينه تلقائيًا بناءً على عدد البذور.

**وصف الكود**:
تقوم الدالة `_kmeans_plusplus` بتنفيذ الجزء الحسابي لتهيئة مراكز التجميع باستخدام خوارزمية k-means++. تبدأ الدالة باختيار المركز الأول بشكل عشوائي من البيانات، ثم تقوم باختيار المراكز المتبقية بناءً على الاحتمالية المتناسبة مع المسافة التربيعية لأقرب مركز موجود. يتم ذلك من خلال إجراء عدد من المحاولات المحلية (`n_local_trials`) لاختيار المراكز التي تقلل من القصور الذاتي (inertia) بشكل أكبر.

تستخدم الدالة أيضًا أوزان العينات (`sample_weight`) لضمان أن عملية الاختيار تأخذ في الاعتبار الأوزان النسبية للنقاط. يتم حساب المسافات الإقليدية التربيعية بين النقاط والمراكز باستخدام الدالة `_euclidean_distances`، ويتم تحديث أقرب المسافات التربيعية والطاقة الحالية (`current_pot`) في كل خطوة.

في المشروع، يتم استدعاء هذه الدالة من قبل الدالة `kmeans_plusplus` التي تقوم بتهيئة البذور الأولية للتجميع باستخدام خوارزمية k-means++. كما يتم استدعاؤها أيضًا من قبل الدالة `_init_centroids` في الكلاس `_BaseKMeans` لتهيئة المراكز الأولية للتجميع بناءً على الطريقة المحددة (`init`).

**ملاحظات**:
- يجب أن تكون البيانات المدخلة (`X`) قد تم التحقق من صحتها مسبقًا.
- إذا لم يتم تحديد `n_local_trials`، يتم تعيينه تلقائيًا بناءً على عدد البذور باستخدام الصيغة `2 + int(np.log(n_clusters))`.
- الدالة تعمل مع كل من المصفوفات الكثيفة والمتفرقة.

**مثال للإخراج**:
```python
centers = array([[1.5, 2.0],
                 [4.5, 3.0]])
indices = array([0, 5])
```
حيث `centers` هي مصفوفة تحتوي على المراكز الأولية للتجميع، و`indices` هي مصفوفة تحتوي على مواقع هذه المراكز في مصفوفة البيانات الأصلية `X`.
## FunctionDef _tolerance(X, tol)
**_tolerance**: وظيفة `_tolerance` هي حساب قيمة التسامح (tolerance) التي تعتمد على مجموعة البيانات المقدمة.

**parameters**: معاملات هذه الوظيفة.
· `X`: مصفوفة البيانات التي يتم حساب التسامح بناءً عليها. يمكن أن تكون هذه المصفوفة إما كثيفة (dense) أو متفرقة (sparse).
· `tol`: قيمة التسامح المطلوبة. إذا كانت هذه القيمة تساوي صفرًا، فإن الوظيفة ترجع صفرًا مباشرةً دون أي حسابات إضافية.

**Code Description**: تقوم هذه الوظيفة بحساب قيمة التسامح بناءً على تباين (variance) مجموعة البيانات المقدمة. إذا كانت قيمة `tol` تساوي صفرًا، فإن الوظيفة ترجع صفرًا مباشرةً. إذا كانت المصفوفة `X` متفرقة (sparse)، يتم حساب التباين باستخدام الدالة `mean_variance_axis` من مكتبة `scipy.sparse`. إذا كانت المصفوفة كثيفة (dense)، يتم حساب التباين باستخدام الدالة `np.var` من مكتبة `numpy`. بعد ذلك، يتم حساب متوسط التباين وضربه في قيمة `tol` للحصول على قيمة التسامح النهائية.

في المشروع، يتم استدعاء هذه الوظيفة من خلال الدالة `_check_params_vs_input` في الكلاس `_BaseKMeans`. يتم استخدام قيمة التسامح المحسوبة هنا لتحديد مدى دقة تجميع البيانات في خوارزمية K-Means. يتم تعيين قيمة التسامح المحسوبة إلى المتغير `self._tol` لاستخدامها لاحقًا في عملية التجميع.

**Note**: 
- إذا كانت مجموعة البيانات تحتوي على تباين منخفض، فإن قيمة التسامح المحسوبة ستكون صغيرة أيضًا.
- إذا كانت المصفوفة `X` متفرقة، تأكد من أن المكتبة `scipy.sparse` مثبتة ومتاحة للاستخدام.

**Output Example**: إذا كانت مجموعة البيانات تحتوي على تباين متوسط قيمته 2.5 وقيمة `tol` هي 0.01، فإن الوظيفة سترجع القيمة `0.025`.
## FunctionDef k_means(X, n_clusters)
**k_means**: وظيفة `k_means` هي تنفيذ خوارزمية التجميع K-Means لتقسيم البيانات إلى عدد محدد من العناقيد (clusters) بناءً على المسافات بين النقاط ومراكز العناقيد.

**parameters**: معاملات هذه الوظيفة.
· `X`: مصفوفة أو مصفوفة متفرقة من الشكل (n_samples, n_features) تحتوي على العينات المراد تجميعها. يجب أن تكون البيانات بتنسيق C لتجنب نسخ الذاكرة إذا لم تكن متوافقة مع C.
· `n_clusters`: عدد العناقيد المطلوب تكوينها.
· `sample_weight`: مصفوفة من الشكل (n_samples,) تحتوي على الأوزان لكل عينة في `X`. إذا كانت القيمة `None`، يتم تعيين وزن متساوٍ لجميع العينات.
· `init`: طريقة تهيئة المراكز الأولية للعناقيد. يمكن أن تكون "k-means++"، "random"، أو مصفوفة أو دالة. القيمة الافتراضية هي "k-means++".
· `n_init`: عدد المرات التي سيتم فيها تشغيل الخوارزمية ببذور أولية مختلفة. القيمة الافتراضية هي "auto".
· `max_iter`: الحد الأقصى لعدد التكرارات لتشغيل الخوارزمية. القيمة الافتراضية هي 300.
· `verbose`: مستوى التفاصيل المطبوعة أثناء التشغيل. القيمة الافتراضية هي False.
· `tol`: قيمة التسامح (tolerance) لتحديد متى تتوقف الخوارزمية عن العمل. القيمة الافتراضية هي 1e-4.
· `random_state`: لتحديد العشوائية في التهيئة. القيمة الافتراضية هي None.
· `copy_x`: إذا كان True، يتم نسخ البيانات الأصلية قبل التعديل. القيمة الافتراضية هي True.
· `algorithm`: الخوارزمية المستخدمة. يمكن أن تكون "lloyd" أو "elkan". القيمة الافتراضية هي "lloyd".
· `return_n_iter`: إذا كان True، يتم إرجاع عدد التكرارات التي تم تنفيذها. القيمة الافتراضية هي False.

**Code Description**: 
تقوم وظيفة `k_means` بتنفيذ خوارزمية التجميع K-Means باستخدام فئة `KMeans` من المشروع. يتم إنشاء كائن من فئة `KMeans` باستخدام المعلمات المدخلة، ثم يتم استدعاء دالة `fit` على البيانات المدخلة (`X`) مع الأوزان (`sample_weight` إذا تم توفيرها). 

بعد تنفيذ الخوارزمية، يتم إرجاع النتائج التالية:
- `centroid`: مصفوفة من الشكل (n_clusters, n_features) تحتوي على مراكز العناقيد التي تم العثور عليها في التكرار الأخير.
- `label`: مصفوفة من الشكل (n_samples,) تحتوي على الفهرس الخاص بالعنقود الذي تنتمي إليه كل عينة.
- `inertia`: القيمة النهائية لمعيار القصور الذاتي (مجموع المسافات التربيعية بين النقاط ومراكز العناقيد).
- `best_n_iter`: عدد التكرارات التي تم تنفيذها للحصول على أفضل نتيجة. يتم إرجاع هذا فقط إذا كان `return_n_iter` مضبوطًا على True.

تستخدم هذه الوظيفة فئة `KMeans` لتنفيذ الخوارزمية، حيث تقوم `KMeans` بتهيئة المراكز الأولية وتشغيل الخوارزمية عدة مرات (`n_init`) مع بذور أولية مختلفة، ثم اختيار أفضل نتيجة بناءً على قيمة القصور الذاتي (`inertia`).

**Note**: 
- يجب أن تكون البيانات بتنسيق C لتجنب نسخ الذاكرة.
- إذا كانت الخوارزمية المحددة هي `"elkan"` وعدد العناقيد يساوي 1، سيتم تغييرها تلقائيًا إلى `"lloyd"`.
- يتم إصدار تحذير إذا كان عدد العناقيد المميزة أقل من `n_clusters`.

**Output Example**: 
```python
centroid = array([[1.2, 3.4], [5.6, 7.8]])
label = array([0, 1, 0, 1], dtype=int32)
inertia = 123.45
best_n_iter = 10
```
## FunctionDef _kmeans_single_elkan(X, sample_weight, centers_init, max_iter, verbose, tol, n_threads)
**_kmeans_single_elkan**: وظيفة `_kmeans_single_elkan` هي تنفيذ خوارزمية k-means باستخدام طريقة Elkan، وهي طريقة محسنة لتسريع عملية التجميع عن طريق تقليل عدد الحسابات المطلوبة للمسافات بين النقاط والمراكز.

**parameters**: معاملات هذه الوظيفة:
· `X`: مصفوفة من الشكل (n_samples, n_features) تحتوي على العينات المراد تجميعها. يمكن أن تكون المصفوفة sparse، وفي هذه الحالة يجب أن تكون بتنسيق CSR.
· `sample_weight`: مصفوفة من الشكل (n_samples,) تحتوي على الأوزان لكل عينة في `X`.
· `centers_init`: مصفوفة من الشكل (n_clusters, n_features) تحتوي على المراكز الأولية للتجميع.
· `max_iter`: عدد صحيح يحدد الحد الأقصى لعدد التكرارات التي ستقوم بها الخوارزمية. القيمة الافتراضية هي 300.
· `verbose`: قيمة منطقية تحدد ما إذا كان سيتم عرض تفاصيل التقدم أثناء التنفيذ. القيمة الافتراضية هي `False`.
· `tol`: قيمة عشرية تحدد الحد الأدنى للتغيير في المراكز بين التكرارات لإعلان التقارب. القيمة الافتراضية هي 1e-4.
· `n_threads`: عدد صحيح يحدد عدد خيوط OpenMP التي سيتم استخدامها للحساب. القيمة الافتراضية هي 1.

**Code Description**: تقوم هذه الوظيفة بتنفيذ خوارزمية k-means باستخدام طريقة Elkan، والتي تعتمد على تقليل عدد حسابات المسافات عن طريق استخدام حدود علوية وسفلية للمسافات بين النقاط والمراكز. يتم ذلك عن طريق:
1. تهيئة المتغيرات والذاكرة المؤقتة اللازمة مثل `centers_new`، `weight_in_clusters`، `labels`، وغيرها.
2. حساب المسافات الأولية بين المراكز وإنشاء حدود علوية وسفلية للمسافات.
3. تنفيذ التكرارات حتى الوصول إلى التقارب أو الوصول إلى الحد الأقصى لعدد التكرارات. في كل تكرار، يتم تحديث المراكز والحدود العلوية والسفلية.
4. التحقق من التقارب بناءً على التغيير في المراكز أو التغيير في التسميات.
5. إعادة حساب التسميات النهائية بعد الوصول إلى التقارب.
6. إرجاع التسميات النهائية، القيمة النهائية لمعيار القصور الذاتي (inertia)، المراكز النهائية، وعدد التكرارات التي تم تنفيذها.

يتم استدعاء هذه الوظيفة من خلال وظيفة `fit` في الكلاس `KMeans`، حيث يتم استخدامها لتشغيل خوارزمية k-means مرة واحدة باستخدام المراكز الأولية المحددة. يتم اختيار أفضل نتيجة بناءً على قيمة القصور الذاتي (inertia) بعد تشغيل الخوارزمية عدة مرات.

**Note**: 
- لا يُنصح بتعيين `tol=0` لأنه قد يؤدي إلى عدم إعلان التقارب أبدًا بسبب أخطاء التقريب.
- يجب أن تكون المصفوفة `X` بتنسيق CSR إذا كانت sparse.
- يمكن زيادة الأداء عن طريق زيادة عدد الخيوط (`n_threads`) إذا كان النظام يدعم OpenMP.

**Output Example**: 
```python
(
    array([0, 1, 0, 1, 0], dtype=int32),  # التسميات النهائية
    123.45,  # القيمة النهائية لمعيار القصور الذاتي
    array([[1.2, 3.4], [5.6, 7.8]]),  # المراكز النهائية
    10  # عدد التكرارات التي تم تنفيذها
)
```
## FunctionDef _kmeans_single_lloyd(X, sample_weight, centers_init, max_iter, verbose, tol, n_threads)
**_kmeans_single_lloyd**: وظيفة `_kmeans_single_lloyd` هي تنفيذ خوارزمية k-means باستخدام طريقة Lloyd لمرة واحدة، مع افتراض أن البيانات قد تم إعدادها مسبقًا.

**المعلمات**:
· `X`: مصفوفة أو مصفوفة متفرقة (sparse matrix) من الشكل (n_samples, n_features) تحتوي على العينات المراد تجميعها. إذا كانت المصفوفة متفرقة، فيجب أن تكون بتنسيق CSR.
· `sample_weight`: مصفوفة من الشكل (n_samples,) تحتوي على الأوزان لكل عينة في `X`.
· `centers_init`: مصفوفة من الشكل (n_clusters, n_features) تحتوي على المراكز الأولية للتجميع.
· `max_iter`: عدد صحيح، القيمة الافتراضية هي 300، وهو الحد الأقصى لعدد التكرارات التي ستقوم الخوارزمية بتنفيذها.
· `verbose`: قيمة منطقية، القيمة الافتراضية هي `False`، وتحدد ما إذا كان سيتم عرض تفاصيل التنفيذ أثناء العملية.
· `tol`: قيمة عشرية، القيمة الافتراضية هي 1e-4، وهي الحد الأدنى للتحمل النسبي لتحديد التقارب بناءً على الفرق في المراكز بين التكرارات المتتالية.
· `n_threads`: عدد صحيح، القيمة الافتراضية هي 1، وهو عدد خيوط OpenMP المستخدمة في الحسابات.

**وصف الكود**:
تقوم الدالة `_kmeans_single_lloyd` بتنفيذ خوارزمية k-means باستخدام طريقة Lloyd لمرة واحدة. تبدأ الخوارزمية بالمراكز الأولية المحددة (`centers_init`) وتقوم بتحديث المراكز وتخصيص العينات إلى أقرب مركز في كل تكرار. يتم إيقاف الخوارزمية إما عند الوصول إلى الحد الأقصى للتكرارات (`max_iter`) أو عند تحقيق التقارب بناءً على القيمة المحددة للتحمل (`tol`).

يتم استخدام دالة `lloyd_iter` لتحديث المراكز والتسميات في كل تكرار، حيث يتم اختيار الدالة المناسبة بناءً على ما إذا كانت البيانات متفرقة (`lloyd_iter_chunked_sparse`) أو كثيفة (`lloyd_iter_chunked_dense`). يتم حساب القصور الذاتي (`inertia`) في كل تكرار إذا كان الوضع التفصيلي (`verbose`) مفعلًا.

في حالة عدم تحقيق التقارب الصارم (أي عدم تغير التسميات بين التكرارات)، يتم التحقق من التقارب بناءً على تحول المراكز (`center_shift`). إذا كان تحول المراكز أقل من أو يساوي قيمة التحمل (`tol`)، يتم إيقاف الخوارزمية.

في النهاية، يتم إعادة تشغيل خطوة التخصيص (E-step) لضمان تطابق التسميات مع المراكز النهائية.

**العلاقة مع الكائنات الأخرى**:
يتم استدعاء هذه الدالة من خلال الكائن `KMeans` في الدالة `fit`، حيث يتم استخدامها لتشغيل خوارزمية k-means لمرة واحدة لكل تهيئة أولية. يتم اختيار هذه الدالة إذا كانت الخوارزمية المحددة هي `lloyd` بدلاً من `elkan`.

**ملاحظات**:
- لا يُنصح بتعيين `tol=0` لأنه قد يؤدي إلى عدم تحقيق التقارب أبدًا بسبب أخطاء التقريب.
- يتم استخدام `n_threads` للتحكم في التوازي أثناء تنفيذ الخوارزمية.

**مثال للإخراج**:
```python
labels = array([0, 1, 0, 1, 2, ...])  # تسميات العينات
inertia = 123.45  # قيمة القصور الذاتي النهائية
centers = array([[1.2, 3.4], [4.5, 5.6], [7.8, 8.9]])  # المراكز النهائية
n_iter = 100  # عدد التكرارات التي تم تنفيذها
```
## FunctionDef _labels_inertia(X, sample_weight, centers, n_threads, return_inertia)
**_labels_inertia**: وظيفة `_labels_inertia` هي تنفيذ الخطوة E (E-step) من خوارزمية EM الخاصة بـ K-means، حيث تقوم بحساب التسميات (labels) والقصور الذاتي (inertia) للعينات المعطاة بالنسبة إلى المراكز (centers).

**parameters**: معاملات هذه الوظيفة:
· `X`: مصفوفة أو مصفوفة稀疏 (sparse matrix) من الشكل (n_samples, n_features)، تمثل العينات المدخلة التي سيتم تعيين التسميات لها. إذا كانت المصفوفة sparse، فيجب أن تكون بتنسيق CSR.
· `sample_weight`: مصفوفة من الشكل (n_samples,)، تمثل الأوزان لكل عينة في `X`.
· `centers`: مصفوفة من الشكل (n_clusters, n_features)، تمثل مراكز العناقيد (clusters).
· `n_threads`: عدد صحيح، القيمة الافتراضية هي 1، يمثل عدد خيوط OpenMP المستخدمة في الحساب. يتم التوازي على مستوى العينات في الحلقة الرئيسية التي تعين كل عينة إلى أقرب مركز.
· `return_inertia`: قيمة منطقية، القيمة الافتراضية هي `True`، تحدد ما إذا كان سيتم حساب وإرجاع القصور الذاتي (inertia).

**Code Description**: 
تقوم هذه الوظيفة بتنفيذ الخطوة E من خوارزمية K-means، حيث يتم تعيين كل عينة إلى أقرب مركز عنقودي بناءً على المسافة الإقليدية. يتم ذلك باستخدام دالة `lloyd_iter_chunked_sparse` إذا كانت المصفوفة `X` sparse، أو `lloyd_iter_chunked_dense` إذا كانت المصفوفة dense. بعد ذلك، يتم حساب القصور الذاتي (inertia) إذا كانت المعلمة `return_inertia` مضبوطة على `True`، وهو مجموع مربعات المسافات بين العينات وأقرب مركز عنقودي لها.

في المشروع، يتم استدعاء هذه الوظيفة من قبل وظيفتين أخريين:
1. `_labels_inertia_threadpool_limit`: تقوم بتنفيذ نفس الوظيفة ولكن في سياق `threadpool_limits` لتقييد عدد الخيوط المستخدمة في العمليات الحسابية.
2. `_mini_batch_step`: تستخدم هذه الوظيفة `_labels_inertia` لحساب التسميات والقصور الذاتي كجزء من خطوة التحديث التزايدي في خوارزمية MiniBatch K-Means.

**Note**: 
- إذا كانت المصفوفة `X` sparse، فيجب أن تكون بتنسيق CSR لضمان الأداء الأمثل.
- يمكن التحكم في عدد الخيوط المستخدمة في الحساب عبر المعلمة `n_threads`، مما يسمح بتحسين الأداء على الأنظمة متعددة النوى.

**Output Example**: 
إذا كانت `return_inertia` مضبوطة على `True`، فإن الإخراج سيكون على الشكل التالي:
```python
(labels, inertia)
```
حيث `labels` هي مصفوفة من الشكل (n_samples,) تحتوي على التسميات المعينة لكل عينة، و`inertia` هو عدد عشري يمثل القصور الذاتي. إذا كانت `return_inertia` مضبوطة على `False`، فإن الإخراج سيكون فقط مصفوفة `labels`.
## FunctionDef _labels_inertia_threadpool_limit(X, sample_weight, centers, n_threads, return_inertia)
**_labels_inertia_threadpool_limit**: وظيفة `_labels_inertia_threadpool_limit` هي تنفيذ وظيفة `_labels_inertia` ولكن في سياق `threadpool_limits` لتقييد عدد الخيوط المستخدمة في العمليات الحسابية.

**parameters**: معاملات هذه الوظيفة:
· `X`: مصفوفة أو مصفوفة sparse من الشكل (n_samples, n_features)، تمثل العينات المدخلة التي سيتم تعيين التسميات لها. إذا كانت المصفوفة sparse، فيجب أن تكون بتنسيق CSR.
· `sample_weight`: مصفوفة من الشكل (n_samples,)، تمثل الأوزان لكل عينة في `X`.
· `centers`: مصفوفة من الشكل (n_clusters, n_features)، تمثل مراكز العناقيد (clusters).
· `n_threads`: عدد صحيح، القيمة الافتراضية هي 1، يمثل عدد خيوط OpenMP المستخدمة في الحساب.
· `return_inertia`: قيمة منطقية، القيمة الافتراضية هي `True`، تحدد ما إذا كان سيتم حساب وإرجاع القصور الذاتي (inertia).

**Code Description**: 
تقوم هذه الوظيفة بتنفيذ نفس الوظيفة التي تقوم بها `_labels_inertia`، ولكنها تقوم بذلك في سياق `threadpool_limits` لتقييد عدد الخيوط المستخدمة في العمليات الحسابية. يتم ذلك باستخدام `threadpool_limits(limits=1, user_api="blas")`، مما يضمن أن عدد الخيوط المستخدمة في العمليات الحسابية لا يتجاوز 1. هذا مفيد في الحالات التي يكون فيها التحكم في عدد الخيوط المستخدمة أمرًا ضروريًا لتحسين الأداء أو لتجنب المشاكل المتعلقة بالتوازي.

بعد ذلك، يتم استدعاء وظيفة `_labels_inertia` مع نفس المعاملات المدخلة، ويتم إرجاع النتيجة التي تنتجها هذه الوظيفة. إذا كانت المعلمة `return_inertia` مضبوطة على `True`، فإن الإخراج سيكون على شكل `(labels, inertia)`، حيث `labels` هي مصفوفة تحتوي على التسميات المعينة لكل عينة، و`inertia` هو القصور الذاتي. إذا كانت `return_inertia` مضبوطة على `False`، فإن الإخراج سيكون فقط مصفوفة `labels`.

في المشروع، يتم استدعاء هذه الوظيفة من قبل عدة وظائف أخرى مثل `predict` و`score` في `_BaseKMeans`، وكذلك في `fit` و`partial_fit` في `MiniBatchKMeans`. هذه الوظائف تستخدم `_labels_inertia_threadpool_limit` لحساب التسميات والقصور الذاتي في سياق محدود الخيوط.

**Note**: 
- يجب أن تكون المصفوفة `X` بتنسيق CSR إذا كانت sparse لضمان الأداء الأمثل.
- يمكن التحكم في عدد الخيوط المستخدمة في الحساب عبر المعلمة `n_threads`، مما يسمح بتحسين الأداء على الأنظمة متعددة النوى.

**Output Example**: 
إذا كانت `return_inertia` مضبوطة على `True`، فإن الإخراج سيكون على الشكل التالي:
```python
(labels, inertia)
```
حيث `labels` هي مصفوفة من الشكل (n_samples,) تحتوي على التسميات المعينة لكل عينة، و`inertia` هو عدد عشري يمثل القصور الذاتي. إذا كانت `return_inertia` مضبوطة على `False`، فإن الإخراج سيكون فقط مصفوفة `labels`.
## ClassDef _BaseKMeans
**_BaseKMeans**: وظيفة الفئة _BaseKMeans هي توفير أساس مشترك لفئات KMeans وMiniBatchKMeans لتجميع البيانات باستخدام خوارزمية K-Means.

**السمات (Attributes)**:
· n_clusters: عدد العناقيد (clusters) المطلوب تكوينها.
· init: طريقة تهيئة المراكز الأولية للعناقيد، يمكن أن تكون "k-means++"، "random"، أو مصفوفة أو دالة.
· n_init: عدد المرات التي سيتم فيها تشغيل الخوارزمية ببذور أولية مختلفة.
· max_iter: الحد الأقصى لعدد التكرارات لتشغيل الخوارزمية.
· tol: قيمة التسامح (tolerance) لتحديد متى تتوقف الخوارزمية عن العمل.
· verbose: مستوى التفاصيل المطبوعة أثناء التشغيل.
· random_state: لتحديد العشوائية في التهيئة.

**وصف الكود**: 
الفئة _BaseKMeans هي فئة أساسية مجردة (abstract base class) توفر الهيكل العام والوظائف المشتركة لفئتي KMeans وMiniBatchKMeans. تحتوي هذه الفئة على طرق للتحقق من صحة المعاملات المدخلة (مثل _check_params_vs_input)، وتهيئة المراكز الأولية للعناقيد (مثل _init_centroids)، والتحقق من شكل المراكز (مثل _validate_center_shape). بالإضافة إلى ذلك، توفر الفئة طرقًا للتنبؤ بالعناقيد (predict)، وتحويل البيانات إلى مسافة العناقيد (transform)، وحساب النتيجة (score).

تتعامل الفئة مع حالات خاصة مثل التحقق من وجود مشاكل في الذاكرة عند استخدام مكتبات معينة مثل MKL وvcomp (من خلال _check_mkl_vcomp و_warn_mkl_vcomp). كما توفر الفئة طرقًا لتنفيذ عمليات التجميع بشكل متزامن (fit_predict وfit_transform).

في المشروع، يتم استخدام هذه الفئة كأساس لفئتي KMeans وMiniBatchKMeans، حيث تقوم الفئتان بتوسيع وظائف _BaseKMeans وإضافة معاملات ووظائف إضافية خاصة بكل منهما. على سبيل المثال، تضيف KMeans معاملات مثل copy_x وalgorithm، بينما تضيف MiniBatchKMeans معاملات مثل batch_size وmax_no_improvement.

**ملاحظات**:
- يجب التأكد من أن عدد العينات أكبر من أو يساوي عدد العناقيد المطلوبة (n_clusters).
- عند استخدام init كدالة أو مصفوفة، يتم تنفيذ تهيئة واحدة فقط بغض النظر عن قيمة n_init.
- يتم إصدار تحذير إذا تم استخدام init كمصفوفة وقيمة n_init أكبر من 1.

**مثال للإخراج**:
عند استخدام الفئة للتنبؤ بالعناقيد، قد يكون الإخراج كالتالي:
```python
array([0, 1, 0, 2, 1], dtype=int32)
```
حيث يمثل كل عنصر في المصفوفة الفهرس الخاص بالعنقود الذي تنتمي إليه العينة المقابلة.
### FunctionDef __init__(self, n_clusters)
**__init__**: وظيفة `__init__` هي تهيئة كائن من الفئة `_BaseKMeans` عن طريق تعيين القيم الأولية للمعلمات المطلوبة لتشغيل خوارزمية K-Means.

**parameters**: معاملات هذه الوظيفة.
· `n_clusters`: عدد العناقيد (clusters) المطلوب إنشاؤها.
· `init`: طريقة تهيئة المراكز الأولية للعناقيد.
· `n_init`: عدد المرات التي سيتم فيها تشغيل الخوارزمية بتهيئات أولية مختلفة.
· `max_iter`: الحد الأقصى لعدد التكرارات المسموح بها للخوارزمية.
· `tol`: قيمة التسامح (tolerance) التي تحدد متى تتوقف الخوارزمية إذا كانت التغييرات في المراكز صغيرة جدًا.
· `verbose`: مستوى التفاصيل المطلوب عرضها أثناء تشغيل الخوارزمية.
· `random_state`: قيمة عشوائية لضمان إمكانية إعادة النتائج عند استخدام نفس القيمة.

**Code Description**: تقوم هذه الوظيفة بتهيئة كائن من الفئة `_BaseKMeans` عن طريق تعيين القيم الممررة كمعاملات إلى السمات (attributes) الخاصة بالكائن. يتم تعيين كل معلمة إلى السمة المقابلة لها في الكائن، مما يسمح باستخدام هذه القيم لاحقًا في عمليات حسابية وتدريب الخوارزمية. على سبيل المثال، يتم تعيين `n_clusters` إلى `self.n_clusters`، و`init` إلى `self.init`، وهكذا لباقي المعاملات. هذه الخطوة ضرورية لضمان أن الكائن يحتوي على جميع المعلومات المطلوبة لتشغيل خوارزمية K-Means بشكل صحيح.

**Note**: عند استخدام هذه الوظيفة، يجب التأكد من تمرير قيم صحيحة ومناسبة للمعلمات، حيث أن هذه القيم تؤثر بشكل مباشر على أداء الخوارزمية. على سبيل المثال، يجب أن تكون قيمة `n_clusters` عددًا صحيحًا موجبًا، وأن تكون قيمة `tol` صغيرة بما يكفي لضمان دقة النتائج ولكن ليست صغيرة جدًا لتجنب التكرارات غير الضرورية.
***
### FunctionDef _check_params_vs_input(self, X, default_n_init)
**_check_params_vs_input**: وظيفة `_check_params_vs_input` هي التحقق من صحة المعلمات المدخلة مقارنةً ببيانات الإدخال `X` وتعديلها إذا لزم الأمر.

**parameters**: معاملات هذه الوظيفة.
· `X`: مصفوفة البيانات التي يتم التحقق منها. يجب أن يكون عدد العينات في `X` أكبر من أو يساوي عدد العناقيد المحدد (`n_clusters`).
· `default_n_init`: القيمة الافتراضية لعدد عمليات التهيئة (`n_init`) في حالة عدم تحديدها بشكل صريح.

**Code Description**: تقوم هذه الوظيفة بالتحقق من عدة معلمات متعلقة بخوارزمية K-Means وتعديلها بناءً على بيانات الإدخال `X`. أولاً، يتم التحقق من أن عدد العينات في `X` أكبر من أو يساوي عدد العناقيد المحدد (`n_clusters`). إذا لم يكن الأمر كذلك، يتم إرجاع خطأ `ValueError`.

بعد ذلك، يتم حساب قيمة التسامح (`tol`) باستخدام الدالة `_tolerance`، والتي تعتمد على تباين البيانات في `X`. يتم تعيين القيمة المحسوبة إلى المتغير `self._tol` لاستخدامها لاحقًا في عملية التجميع.

ثم يتم التحقق من قيمة `n_init`، وهي عدد مرات التهيئة التي سيتم تنفيذها. إذا كانت القيمة `auto`، يتم تحديد عدد المرات بناءً على طريقة التهيئة (`init`). إذا كانت طريقة التهيئة هي `k-means++`، يتم تعيين `n_init` إلى 1. إذا كانت الطريقة هي `random` أو تم تمرير دالة تهيئة مخصصة، يتم استخدام القيمة الافتراضية `default_n_init`. إذا تم تمرير مراكز ابتدائية بشكل صريح (كقائمة أو مصفوفة)، يتم تعيين `n_init` إلى 1 أيضًا.

أخيرًا، إذا تم تمرير مراكز ابتدائية بشكل صريح وتم تحديد `n_init` بقيمة أكبر من 1، يتم إصدار تحذير (`RuntimeWarning`) لتوضيح أنه سيتم تنفيذ تهيئة واحدة فقط بدلاً من القيمة المحددة.

**Note**: 
- تأكد من أن عدد العينات في `X` أكبر من أو يساوي عدد العناقيد المحدد (`n_clusters`) لتجنب الأخطاء.
- إذا كنت تستخدم مراكز ابتدائية محددة مسبقًا، سيتم تنفيذ تهيئة واحدة فقط بغض النظر عن قيمة `n_init` المحددة.
- يتم استخدام قيمة التسامح المحسوبة (`self._tol`) لضمان دقة عملية التجميع في خوارزمية K-Means.
***
### FunctionDef _warn_mkl_vcomp(self, n_active_threads)
**_warn_mkl_vcomp**: وظيفة `_warn_mkl_vcomp` هي إصدار تحذير محدد عندما تكون كل من مكتبة `vcomp` و `mkl` موجودة معًا.

**parameters**: معاملات هذه الوظيفة.
· `n_active_threads`: عدد الخيوط النشطة التي يتم استخدامها في العملية الحسابية.

**Code Description**: 
تُستخدم هذه الوظيفة لإصدار تحذير محدد عندما يتم اكتشاف وجود كل من مكتبة `vcomp` (وهي مكتبة OpenMP الخاصة بمايكروسوفت) ومكتبة `mkl` (وهي مكتبة BLAS الخاصة بإنتل) في نفس البيئة. يتم استدعاء هذه الوظيفة من خلال وظيفة أخرى تسمى `_check_mkl_vcomp`، والتي تقوم بالتحقق من وجود هذه المكتبات وتحديد ما إذا كان هناك حاجة لإصدار تحذير.

عندما يتم استدعاء `_check_mkl_vcomp`، يتم التحقق من عدد العينات (`n_samples`) وحجم القطعة (`CHUNK_SIZE`) لتحديد عدد الخيوط النشطة (`n_active_threads`). إذا كان عدد الخيوط النشطة أقل من عدد الخيوط المتاحة (`self._n_threads`)، يتم التحقق من وجود مكتبة `vcomp` و `mkl` باستخدام وظيفة `threadpool_info()`. إذا تم اكتشاف وجود كلتا المكتبتين، يتم استدعاء `_warn_mkl_vcomp` لإصدار التحذير المناسب.

**Note**: 
- هذا التحذير مهم لأنه يشير إلى وجود مشكلة محتملة في تسرب الذاكرة عند استخدام مكتبة `vcomp` مع `mkl` في حالات معينة، خاصة عندما يكون عدد القطع أقل من عدد الخيوط المتاحة.
- يجب على المطورين الانتباه إلى هذا التحذير واتخاذ الإجراءات المناسبة لتجنب المشكلات المحتملة في الأداء أو استهلاك الذاكرة.
***
### FunctionDef _check_mkl_vcomp(self, X, n_samples)
**_check_mkl_vcomp**: وظيفة `_check_mkl_vcomp` هي التحقق من وجود مكتبتي `vcomp` و `mkl` معًا وإصدار تحذير في حالة وجودهما معًا.

**parameters**: معاملات هذه الوظيفة.
· `X`: مصفوفة البيانات المدخلة التي يتم التحقق منها. يمكن أن تكون هذه المصفوفة كثيفة أو متفرقة.
· `n_samples`: عدد العينات في البيانات المدخلة.

**Code Description**: 
تُستخدم هذه الوظيفة للتحقق من وجود مكتبتي `vcomp` (وهي مكتبة OpenMP الخاصة بمايكروسوفت) و `mkl` (وهي مكتبة BLAS الخاصة بإنتل) معًا في البيئة الحالية. يتم استدعاء هذه الوظيفة في حالات معينة عندما يتم استخدام خوارزمية `KMeans` أو `MiniBatchKMeans`، حيث يتم التحقق من عدد العينات وحجم القطعة (`CHUNK_SIZE`) لتحديد عدد الخيوط النشطة (`n_active_threads`). 

إذا كان عدد الخيوط النشطة أقل من عدد الخيوط المتاحة (`self._n_threads`)، يتم التحقق من وجود مكتبة `vcomp` و `mkl` باستخدام وظيفة `threadpool_info()`. إذا تم اكتشاف وجود كلتا المكتبتين، يتم استدعاء وظيفة `_warn_mkl_vcomp` لإصدار تحذير محدد يشير إلى وجود مشكلة محتملة في تسرب الذاكرة عند استخدام مكتبة `vcomp` مع `mkl` في حالات معينة، خاصة عندما يكون عدد القطع أقل من عدد الخيوط المتاحة.

يتم استدعاء هذه الوظيفة من خلال وظائف `fit` و `partial_fit` في كل من `KMeans` و `MiniBatchKMeans`، حيث يتم التحقق من وجود المكتبات المذكورة قبل تنفيذ العمليات الحسابية الرئيسية.

**Note**: 
- هذا التحذير مهم لأنه يشير إلى وجود مشكلة محتملة في تسرب الذاكرة عند استخدام مكتبة `vcomp` مع `mkl` في حالات معينة، خاصة عندما يكون عدد القطع أقل من عدد الخيوط المتاحة.
- يجب على المطورين الانتباه إلى هذا التحذير واتخاذ الإجراءات المناسبة لتجنب المشكلات المحتملة في الأداء أو استهلاك الذاكرة.

**Output Example**: 
لا تُرجع هذه الوظيفة أي قيمة، ولكنها قد تُصدر تحذيرًا في حالة وجود كل من مكتبتي `vcomp` و `mkl` معًا.
***
### FunctionDef _validate_center_shape(self, X, centers)
**_validate_center_shape**: وظيفة `_validate_center_shape` هي التحقق من توافق شكل مراكز التجميع مع البيانات وعدد العناقيد المحدد.

**المعلمات**:
· `X`: مصفوفة تحتوي على عينات البيانات من الشكل `(n_samples, n_features)`.
· `centers`: مصفوفة تحتوي على مراكز التجميع من الشكل `(n_clusters, n_features)`.

**وصف الكود**: تقوم هذه الوظيفة بالتحقق من أن عدد مراكز التجميع `centers` يتطابق مع عدد العناقيد `n_clusters` المحدد في الكائن. بالإضافة إلى ذلك، تقوم بالتحقق من أن عدد الخصائص (الميزات) في مراكز التجميع يتطابق مع عدد الخصائص في البيانات `X`. إذا لم يتطابق الشكل، يتم إطلاق خطأ `ValueError` مع رسالة توضح سبب عدم التطابق.

يتم استخدام هذه الوظيفة في عدة أماكن داخل المشروع، مثل `_init_centroids` و`fit` و`partial_fit` في كل من `KMeans` و`MiniBatchKMeans`. في هذه الوظائف، يتم استدعاء `_validate_center_shape` للتحقق من صحة مراكز التجميع التي يتم تمريرها كمعلمة `init` أو التي يتم حسابها أثناء عملية التهيئة. هذا يضمن أن مراكز التجميع المقدمة أو المحسوبة تتوافق مع شكل البيانات وعدد العناقيد المطلوب.

**ملاحظة**: يجب أن تكون مراكز التجميع المقدمة أو المحسوبة متوافقة مع شكل البيانات وعدد العناقيد، وإلا سيتم إطلاق خطأ. هذا التحقق ضروري لضمان صحة عملية التجميع وتجنب الأخطاء أثناء التنفيذ.
***
### FunctionDef _check_test_data(self, X)
**_check_test_data**: وظيفة `_check_test_data` هي التحقق من صحة البيانات المدخلة `X` وتأكيد أنها متوافقة مع المتطلبات اللازمة للتنبؤ أو التحويل في خوارزمية K-Means.

**parameters**: معاملات هذه الوظيفة.
· `X`: مصفوفة أو مصفوفة稀疏 (sparse matrix) تحتوي على البيانات الجديدة التي سيتم التحقق منها. يجب أن تكون البيانات من نوع `np.float64` أو `np.float32`.

**Code Description**: تقوم هذه الوظيفة بالتحقق من صحة البيانات المدخلة `X` باستخدام الوظيفة `_validate_data` التي تأتي من الفئة الأساسية. يتم التحقق من أن البيانات مقبولة كـ sparse matrix من نوع `csr`، وأنها من النوع `np.float64` أو `np.float32`، وأنها مرتبة بطريقة `C` (row-major order). بالإضافة إلى ذلك، يتم التأكد من أن البيانات ليست sparse كبيرة الحجم (`accept_large_sparse=False`). 

تُستخدم هذه الوظيفة في عدة وظائف أخرى مثل `predict`، `transform`، و`score` في الفئة `_BaseKMeans`. في كل حالة، يتم استدعاء `_check_test_data` للتحقق من أن البيانات المدخلة `X` صالحة قبل إجراء أي عمليات أخرى مثل التنبؤ بالعناقيد أو تحويل البيانات إلى مسافة العناقيد أو حساب النتيجة.

**Note**: يجب أن تكون البيانات المدخلة `X` متوافقة مع الشروط المذكورة أعلاه، وإلا سيتم رفضها. كما أن هذه الوظيفة لا تقوم بإعادة تعيين (`reset=False`) أي إعدادات داخلية للفئة، مما يعني أنها تحتفظ بالإعدادات الحالية.

**Output Example**: قيمة الإرجاع هي البيانات المدخلة `X` بعد التحقق من صحتها. على سبيل المثال، إذا كانت `X` مصفوفة تحتوي على أرقام عشوية، فستكون القيمة المُرجعة هي نفس المصفوفة ولكن بعد التأكد من أنها متوافقة مع الشروط المطلوبة. مثال:
```python
X_validated = self._check_test_data(X)
# X_validated ستكون مصفوفة من نوع np.float64 أو np.float32
```
***
### FunctionDef _init_centroids(self, X, x_squared_norms, init, random_state, sample_weight, init_size, n_centroids)
**_init_centroids**: وظيفة `_init_centroids` هي حساب المراكز الأولية للتجميع باستخدام طرق مختلفة للتهيئة مثل k-means++ أو التهيئة العشوائية أو تمرير مصفوفة مراكز مسبقة.

**المعلمات**:
· `X`: مصفوفة أو مصفوفة متفرقة (sparse matrix) من الشكل (n_samples, n_features) تمثل عينات البيانات المدخلة.
· `x_squared_norms`: مصفوفة من الشكل (n_samples,) تحتوي على القيم التربيعية للأبعاد الإقليدية لكل نقطة بيانات.
· `init`: طريقة التهيئة، يمكن أن تكون إما 'k-means++' أو 'random' أو دالة قابلة للاستدعاء أو مصفوفة من الشكل (n_clusters, n_features).
· `random_state`: كائن من نوع `RandomState` يستخدم لتوليد الأرقام العشوائية لتهيئة المراكز.
· `sample_weight`: مصفوفة من الشكل (n_samples,) تمثل الأوزان لكل ملاحظة في `X`.
· `init_size`: عدد صحيح اختياري يمثل عدد العينات التي سيتم اختيارها عشوائيًا لتسريع عملية التهيئة.
· `n_centroids`: عدد صحيح اختياري يمثل عدد المراكز التي سيتم تهيئتها. إذا لم يتم تحديده، يتم استخدام عدد العناقيد المحدد في الكائن (`self.n_clusters`).

**وصف الكود**: تقوم الدالة `_init_centroids` بحساب المراكز الأولية للتجميع بناءً على الطريقة المحددة في المعلمة `init`. إذا كانت الطريقة هي 'k-means++'، يتم استدعاء الدالة `_kmeans_plusplus` لحساب المراكز الأولية باستخدام خوارزمية k-means++. إذا كانت الطريقة هي 'random'، يتم اختيار المراكز عشوائيًا من البيانات المدخلة. إذا تم تمرير مصفوفة مراكز مسبقة، يتم استخدامها مباشرة. إذا تم تمرير دالة قابلة للاستدعاء، يتم استدعاؤها لحساب المراكز الأولية.

بالإضافة إلى ذلك، إذا تم تحديد `init_size`، يتم اختيار عينة عشوائية من البيانات لتسريع عملية التهيئة. يتم التحقق من صحة شكل المراكز باستخدام الدالة `_validate_center_shape` للتأكد من توافقها مع شكل البيانات وعدد العناقيد.

في المشروع، يتم استدعاء هذه الدالة من قبل الدالة `fit` في كل من `KMeans` و`MiniBatchKMeans` لتهيئة المراكز الأولية قبل بدء عملية التجميع. كما يتم استدعاؤها أيضًا من قبل الدالة `partial_fit` في `MiniBatchKMeans` عند التهيئة الأولية للتجميع.

**ملاحظات**:
- إذا كانت البيانات متفرقة (sparse)، يتم تحويل المراكز إلى مصفوفة كثيفة (dense array) قبل إرجاعها.
- يجب أن تكون المراكز المقدمة أو المحسوبة متوافقة مع شكل البيانات وعدد العناقيد، وإلا سيتم إطلاق خطأ.
- إذا تم استخدام `init_size`، يجب أن يكون أصغر من عدد العينات في البيانات المدخلة.

**مثال للإخراج**:
```python
centers = array([[1.2, 3.4],
                 [4.5, 6.7],
                 [7.8, 9.0]])
```
حيث `centers` هي مصفوفة تحتوي على المراكز الأولية للتجميع.
***
### FunctionDef fit_predict(self, X, y, sample_weight)
**fit_predict**: وظيفة `fit_predict` هي حساب مراكز العناقيد (clusters) وتوقع الفهرس الخاص بالعنقود لكل عينة في البيانات.

**parameters**: معاملات هذه الوظيفة.
· `X`: مصفوفة أو مصفوفة稀疏 من الشكل (n_samples, n_features)، تمثل البيانات الجديدة التي سيتم تحويلها.
· `y`: مُتجاهَل، موجود فقط للحفاظ على اتساق واجهة البرمجة (API consistency).
· `sample_weight`: مصفوفة من الشكل (n_samples,)، تحدد الأوزان لكل عينة في `X`. إذا كانت القيمة `None`، فإن جميع العينات تُعطى وزنًا متساويًا.

**Code Description**: 
تقوم هذه الوظيفة بحساب مراكز العناقيد وتوقع الفهرس الخاص بالعنقود لكل عينة في البيانات. وهي تعادل استدعاء وظيفة `fit` متبوعة بوظيفة `predict`. يتم ذلك عن طريق استدعاء `fit` على البيانات `X` مع تحديد الأوزان `sample_weight` إذا كانت متوفرة، ثم يتم إرجاع التسميات (labels) التي تمثل الفهرس الخاص بالعنقود لكل عينة.

**Note**: 
- هذه الوظيفة مريحة للاستخدام عندما تريد تنفيذ عمليتي `fit` و `predict` في خطوة واحدة.
- يجب أن تكون البيانات المدخلة `X` متوافقة مع الشكل المطلوب (n_samples, n_features).

**Output Example**: 
مثال على القيمة المُرجعة:
```python
array([0, 1, 0, 2, 1, ...])
```
حيث يمثل كل عنصر في المصفوفة الفهرس الخاص بالعنقود الذي تنتمي إليه العينة المقابلة في البيانات المدخلة `X`.
***
### FunctionDef predict(self, X, sample_weight)
**predict**: وظيفة `predict` هي تحديد أقرب عنقود (cluster) ينتمي إليه كل عينة في البيانات المدخلة `X`.

**parameters**: معاملات هذه الوظيفة:
· `X`: مصفوفة أو مصفوفة sparse من الشكل (n_samples, n_features)، تمثل البيانات الجديدة التي سيتم التنبؤ بالعناقيد لها.
· `sample_weight`: مصفوفة من الشكل (n_samples,)، تمثل الأوزان لكل عينة في `X`. هذه المعلمة مُهملة (deprecated) بدءًا من الإصدار 1.3 وسيتم إزالتها في الإصدار 1.5.

**Code Description**: تقوم وظيفة `predict` بحساب أقرب عنقود لكل عينة في البيانات المدخلة `X` باستخدام مراكز العناقيد (cluster centers) التي تم تعلمها مسبقًا. يتم ذلك من خلال الخطوات التالية:
1. التحقق من أن النموذج قد تم تدريبه مسبقًا باستخدام `check_is_fitted`.
2. التحقق من صحة البيانات المدخلة `X` باستخدام الوظيفة `_check_test_data`، والتي تضمن أن البيانات متوافقة مع المتطلبات اللازمة للتنبؤ.
3. إذا تم تمرير معلمة `sample_weight`، يتم إصدار تحذير يفيد بأن هذه المعلمة مُهملة وسيتم إزالتها في الإصدار 1.5. بعد ذلك، يتم التحقق من صحة الأوزان باستخدام `_check_sample_weight`.
4. يتم حساب التسميات (labels) باستخدام الوظيفة `_labels_inertia_threadpool_limit`، والتي تقوم بحساب أقرب عنقود لكل عينة مع تقييد عدد الخيوط المستخدمة في العمليات الحسابية. يتم تمرير مراكز العناقيد (`self.cluster_centers_`) وعدد الخيوط (`self._n_threads`) كمعاملات لهذه الوظيفة.
5. يتم إرجاع التسميات التي تم حسابها، وهي مصفوفة تحتوي على مؤشرات العناقيد التي تنتمي إليها كل عينة.

**Note**: 
- معلمة `sample_weight` مُهملة ولا ينصح باستخدامها. سيتم إزالتها في الإصدار 1.5.
- يجب أن تكون البيانات المدخلة `X` متوافقة مع الشروط التي يتم التحقق منها في `_check_test_data`، مثل أن تكون من نوع `np.float64` أو `np.float32` وأن تكون مرتبة بطريقة `C`.

**Output Example**: قيمة الإرجاع هي مصفوفة تحتوي على مؤشرات العناقيد لكل عينة. على سبيل المثال، إذا كانت البيانات المدخلة تحتوي على 5 عينات وتم تقسيمها إلى 3 عناقيد، فقد تكون القيمة المُرجعة كالتالي:
```python
array([0, 2, 1, 0, 2])
```
حيث يشير كل عنصر في المصفوفة إلى العنقود الذي تنتمي إليه العينة المقابلة.
***
### FunctionDef fit_transform(self, X, y, sample_weight)
**fit_transform**: وظيفة `fit_transform` هي حساب التجميع (clustering) وتحويل البيانات `X` إلى مسافة الفضاء الخاص بالتجميع.

**parameters**: معاملات هذه الوظيفة.
· `X`: مصفوفة أو مصفوفة稀疏 من الشكل `(n_samples, n_features)`، تمثل البيانات الجديدة التي سيتم تحويلها.
· `y`: مُتجاهَل، موجود فقط للحفاظ على اتساق واجهة البرمجة (API consistency).
· `sample_weight`: مصفوفة من الشكل `(n_samples,)`، تمثل الأوزان لكل عينة في `X`. إذا كانت القيمة `None`، فإن جميع العينات تُعطى وزنًا متساويًا.

**Code Description**: 
تقوم هذه الوظيفة بحساب التجميع (clustering) للبيانات `X` باستخدام خوارزمية K-Means، ثم تحويل البيانات إلى مسافة الفضاء الخاص بالتجميع. يتم ذلك بشكل أكثر كفاءة من خلال تنفيذ `fit(X)` متبوعًا بـ `transform(X)` في خطوة واحدة. 

الوظيفة تستدعي أولاً `fit(X, sample_weight=sample_weight)` لتجهيز النموذج بناءً على البيانات المدخلة `X` والأوزان الاختيارية `sample_weight`. بعد ذلك، تقوم باستدعاء `_transform(X)` لتحويل البيانات إلى مسافة الفضاء الخاص بالتجميع. النتيجة النهائية هي مصفوفة جديدة تمثل البيانات المحولة في الفضاء الجديد.

**Note**: 
- هذه الوظيفة تعادل تنفيذ `fit(X)` متبوعًا بـ `transform(X)`، ولكنها أكثر كفاءة من حيث الأداء.
- إذا كنت بحاجة فقط إلى تحويل البيانات دون إعادة تدريب النموذج، يمكن استخدام `transform(X)` مباشرةً.

**Output Example**: 
مثال على القيمة المُرجعة يمكن أن يكون مصفوفة من الشكل `(n_samples, n_clusters)`، حيث تمثل كل صف عينة وكل عمود المسافة إلى مركز التجميع المقابل. على سبيل المثال:
```
array([[0.5, 1.2, 0.8],
       [1.0, 0.7, 1.5],
       [0.3, 1.1, 0.9]])
```
هذه المصفوفة تمثل ثلاث عينات وثلاثة تجمعات، حيث تشير القيم إلى المسافات بين كل عينة ومراكز التجميع.
***
### FunctionDef transform(self, X)
**transform**: وظيفة `transform` هي تحويل البيانات `X` إلى فضاء جديد يعبر عن المسافات بين نقاط البيانات ومراكز العناقيد.

**parameters**: معاملات هذه الوظيفة.
· `X`: مصفوفة أو مصفوفة sparse تحتوي على البيانات الجديدة التي سيتم تحويلها. يجب أن تكون ذات شكل `(n_samples, n_features)`.

**Code Description**: تقوم هذه الوظيفة بتحويل البيانات المدخلة `X` إلى فضاء جديد حيث يمثل كل بعد في هذا الفضاء المسافة بين نقطة البيانات ومركز عنقودي محدد. يتم ذلك عن طريق حساب المسافات الإقليدية بين نقاط البيانات ومراكز العناقيد المخزنة في النموذج. 

تبدأ الوظيفة بالتحقق من أن النموذج قد تم تدريبه مسبقًا باستخدام `check_is_fitted`. بعد ذلك، يتم التحقق من صحة البيانات المدخلة `X` باستخدام الوظيفة `_check_test_data`، والتي تضمن أن البيانات متوافقة مع المتطلبات اللازمة للتحويل، مثل نوع البيانات (`np.float64` أو `np.float32`) وترتيبها (`C-order`). 

بعد التحقق من صحة البيانات، يتم تمريرها إلى الوظيفة `_transform` التي تقوم بحساب المسافات الإقليدية بين نقاط البيانات ومراكز العناقيد باستخدام دالة `euclidean_distances`. النتيجة النهائية هي مصفوفة جديدة تحتوي على المسافات بين كل نقطة بيانات وكل مركز عنقودي، مما يعبر عن قرب كل نقطة بيانات من كل عنقود.

**Note**: 
- حتى إذا كانت البيانات المدخلة `X` sparse، فإن المصفوفة التي يتم إرجاعها ستكون عادةً كثيفة (`dense`).
- يجب أن تكون البيانات المدخلة متوافقة مع الشروط المذكورة أعلاه، وإلا سيتم رفضها.

**Output Example**: إذا كانت `X` تحتوي على 3 نقاط بيانات وعدد العناقيد هو 2، فإن النتيجة قد تكون كالتالي:
```python
array([[1.2, 0.8],
       [0.5, 1.1],
       [1.0, 0.9]])
```
حيث يمثل كل صف المسافات بين نقطة البيانات ومراكز العناقيد.
***
### FunctionDef _transform(self, X)
**_transform**: وظيفة `_transform` هي حساب المسافات الإقليدية بين نقاط البيانات ومراكز العناقيد (cluster centers).

**parameters**: معاملات هذه الوظيفة.
· `X`: مصفوفة أو مصفوفة稀疏 تحتوي على نقاط البيانات التي سيتم تحويلها إلى مسافات من مراكز العناقيد. يجب أن تكون ذات شكل `(n_samples, n_features)`.

**Code Description**: تقوم هذه الوظيفة بحساب المسافات الإقليدية بين كل نقطة بيانات في المصفوفة `X` ومراكز العناقيد المخزنة في `self.cluster_centers_`. يتم استخدام دالة `euclidean_distances` من مكتبة `scikit-learn` لحساب هذه المسافات. النتيجة هي مصفوفة جديدة تحتوي على المسافات بين كل نقطة بيانات وكل مركز عنقودي، مما يسمح بتحويل البيانات إلى فضاء جديد يعبر عن قربها من كل عنقود.

هذه الوظيفة تُستدعى من خلال وظيفة `transform` في الكلاس `_BaseKMeans`. حيث تقوم `transform` بالتحقق من أن النموذج قد تم تدريبه (`check_is_fitted`) وتقوم بفحص البيانات المدخلة (`_check_test_data`) قبل تمريرها إلى `_transform`. وبالتالي، فإن `_transform` هي الجزء الأساسي الذي ينفذ العملية الحسابية الرئيسية لتحويل البيانات.

**Note**: 
- هذه الوظيفة لا تقوم بأي تحقق من صحة المدخلات (`no input validation`)، لذا يجب التأكد من أن البيانات المدخلة صحيحة قبل استخدامها.
- النتيجة التي يتم إرجاعها ستكون مصفوفة كثيفة (`dense array`) حتى إذا كانت البيانات المدخلة sparse.

**Output Example**: 
إذا كانت `X` تحتوي على 3 نقاط بيانات وعدد العناقيد هو 2، فإن النتيجة قد تكون كالتالي:
```python
array([[1.2, 0.8],
       [0.5, 1.1],
       [1.0, 0.9]])
```
حيث يمثل كل صف المسافات بين نقطة البيانات ومراكز العناقيد.
***
### FunctionDef score(self, X, y, sample_weight)
**score**: وظيفة `score` تقوم بحساب القيمة المعاكسة لقيمة الهدف (objective) لخوارزمية K-means على البيانات المدخلة `X`.

**parameters**: معاملات هذه الوظيفة:
· `X`: مصفوفة أو مصفوفة sparse من الشكل (n_samples, n_features)، تمثل البيانات الجديدة التي سيتم تقييمها.
· `y`: يتم تجاهله، موجود هنا للحفاظ على اتساق واجهة البرمجة (API consistency).
· `sample_weight`: مصفوفة من الشكل (n_samples,)، القيمة الافتراضية هي `None`، تمثل الأوزان لكل عينة في `X`. إذا كانت القيمة `None`، يتم تعيين وزن متساوٍ لجميع العينات.

**Code Description**: 
تقوم هذه الوظيفة بحساب القيمة المعاكسة لقيمة الهدف لخوارزمية K-means على البيانات المدخلة `X`. يتم ذلك عبر الخطوات التالية:
1. التحقق من أن النموذج قد تم تدريبه مسبقًا باستخدام `check_is_fitted`.
2. التحقق من صحة البيانات المدخلة `X` باستخدام `_check_test_data`، والتي تضمن أن البيانات متوافقة مع المتطلبات اللازمة للتنبؤ أو التحويل في خوارزمية K-means.
3. التحقق من أوزان العينات `sample_weight` باستخدام `_check_sample_weight`، والتي تضمن أن الأوزان صالحة وإذا كانت `None`، يتم تعيين وزن متساوٍ لجميع العينات.
4. حساب التسميات والقصور الذاتي (inertia) باستخدام `_labels_inertia_threadpool_limit`، والتي تقوم بحساب هذه القيم في سياق محدود الخيوط (threadpool_limits) لضمان التحكم في عدد الخيوط المستخدمة في العمليات الحسابية.
5. إرجاع القيمة المعاكسة للقصور الذاتي (inertia) كقيمة النتيجة.

تُستخدم هذه الوظيفة في تقييم أداء النموذج على البيانات الجديدة، حيث تعكس القيمة المُرجعة مدى قرب البيانات من مراكز العناقيد (clusters) التي تم تعلمها أثناء التدريب.

**Note**: 
- يجب أن تكون البيانات المدخلة `X` متوافقة مع الشروط المطلوبة، مثل أن تكون من نوع `np.float64` أو `np.float32` وأن تكون مرتبة بطريقة `C` (row-major order).
- إذا كانت البيانات sparse، فيجب أن تكون بتنسيق CSR لضمان الأداء الأمثل.

**Output Example**: 
القيمة المُرجعة هي عدد عشري يمثل القيمة المعاكسة للقصور الذاتي. على سبيل المثال:
```python
score_value = model.score(X)
# score_value قد تكون قيمة مثل -123.45
```
***
### FunctionDef _more_tags(self)
**_more_tags**: وظيفة `_more_tags` هي إرجاع معلومات إضافية حول الكائن الحالي، وتحديدًا فيما يتعلق بالاختبارات التي قد تفشل (fail) في ظروف معينة.

**parameters**: لا تحتوي هذه الدالة على أي معاملات (parameters).

**Code Description**: تقوم الدالة `_more_tags` بإرجاع قاموس (dictionary) يحتوي على معلومات إضافية تُستخدم عادةً في سياق الاختبارات (testing). في هذه الحالة، يتم تحديد أن الاختبار المسمى `check_sample_weights_invariance` قد يفشل (fail) في ظروف معينة. السبب المحدد لفشل هذا الاختبار هو أن استخدام وزن عينة (sample_weight) بقيمة صفر (zero) لا يعادل إزالة العينات (removing samples) من البيانات. يتم تمثيل هذه المعلومات في القاموس تحت المفتاح `_xfail_checks`.

**Note**: هذه الدالة تُستخدم بشكل رئيسي في إطار اختبارات البرمجيات (software testing) لتوفير معلومات إضافية حول السلوك المتوقع للكائن في حالات معينة. يجب على المطورين مراعاة هذه المعلومات عند كتابة أو تشغيل الاختبارات.

**Output Example**: 
```python
{
    "_xfail_checks": {
        "check_sample_weights_invariance": (
            "zero sample_weight is not equivalent to removing samples"
        ),
    },
}
```
***
## ClassDef KMeans
**KMeans**: وظيفة KMeans هي تنفيذ خوارزمية التجميع K-Means لتقسيم البيانات إلى عدد محدد من العناقيد (clusters) بناءً على المسافات بين النقاط ومراكز العناقيد.

**السمات (Attributes)**:
· n_clusters: عدد العناقيد المطلوب تكوينها. القيمة الافتراضية هي 8.
· init: طريقة تهيئة المراكز الأولية للعناقيد. يمكن أن تكون "k-means++"، "random"، أو مصفوفة أو دالة. القيمة الافتراضية هي "k-means++".
· n_init: عدد المرات التي سيتم فيها تشغيل الخوارزمية ببذور أولية مختلفة. القيمة الافتراضية هي "auto".
· max_iter: الحد الأقصى لعدد التكرارات لتشغيل الخوارزمية. القيمة الافتراضية هي 300.
· tol: قيمة التسامح (tolerance) لتحديد متى تتوقف الخوارزمية عن العمل. القيمة الافتراضية هي 1e-4.
· verbose: مستوى التفاصيل المطبوعة أثناء التشغيل. القيمة الافتراضية هي 0.
· random_state: لتحديد العشوائية في التهيئة. القيمة الافتراضية هي None.
· copy_x: إذا كان True، يتم نسخ البيانات الأصلية قبل التعديل. القيمة الافتراضية هي True.
· algorithm: الخوارزمية المستخدمة. يمكن أن تكون "lloyd" أو "elkan". القيمة الافتراضية هي "lloyd".

**وصف الكود**: 
فئة KMeans هي فئة تقوم بتنفيذ خوارزمية التجميع K-Means، وهي إحدى أشهر خوارزميات التجميع غير الموجهة (unsupervised clustering). تقوم الخوارزمية بتقسيم البيانات إلى عدد محدد من العناقيد بناءً على المسافات بين النقاط ومراكز العناقيد. يتم تحسين مراكز العناقيد بشكل متكرر حتى يتم تحقيق التقارب أو الوصول إلى الحد الأقصى لعدد التكرارات.

الفئة ترث من الفئة الأساسية _BaseKMeans، والتي توفر الهيكل العام والوظائف المشتركة لفئتي KMeans وMiniBatchKMeans. تحتوي الفئة على معلمات إضافية مثل copy_x وalgorithm، والتي تتحكم في سلوك الخوارزمية.

عند استدعاء دالة fit، يتم تنفيذ الخوارزمية على البيانات المدخلة X. يتم حساب المراكز الأولية باستخدام الطريقة المحددة في init، ثم يتم تحسين هذه المراكز بشكل متكرر حتى يتم تحقيق التقارب. يتم تخزين النتائج النهائية في السمات cluster_centers_ (مراكز العناقيد)، labels_ (تسميات العناقيد لكل نقطة)، و inertia_ (مجموع المسافات التربيعية بين النقاط ومراكز العناقيد).

الفئة تدعم أيضًا خوارزميتين رئيسيتين: "lloyd" (الكلاسيكية) و"elkan" (الأكثر كفاءة في بعض الحالات ولكنها تستهلك ذاكرة أكثر). يتم التحقق من المعلمات المدخلة باستخدام _check_params_vs_input، ويتم إصدار تحذيرات في حالات معينة مثل استخدام خوارزمية "elkan" مع عنقود واحد فقط.

**ملاحظات**:
- يجب التأكد من أن عدد العينات أكبر من أو يساوي عدد العناقيد المطلوبة (n_clusters).
- عند استخدام init كدالة أو مصفوفة، يتم تنفيذ تهيئة واحدة فقط بغض النظر عن قيمة n_init.
- يتم إصدار تحذير إذا تم استخدام init كمصفوفة وقيمة n_init أكبر من 1.
- في حالة استخدام خوارزمية "elkan"، يتم إصدار تحذير إذا كان عدد العناقيد يساوي 1.

**مثال للإخراج**:
عند استخدام الفئة للتنبؤ بالعناقيد، قد يكون الإخراج كالتالي:
```python
array([0, 1, 0, 2, 1], dtype=int32)
```
حيث يمثل كل عنصر في المصفوفة الفهرس الخاص بالعنقود الذي تنتمي إليه العينة المقابلة.
### FunctionDef __init__(self, n_clusters)
**__init__**: وظيفة `__init__` هي تهيئة كائن من فئة KMeans مع تعيين القيم الافتراضية أو المحددة للمعلمات المطلوبة لتشغيل خوارزمية K-Means.

**parameters**: معاملات هذه الوظيفة.
· `n_clusters`: عدد العناقيد (clusters) المطلوبة. القيمة الافتراضية هي 8.
· `init`: طريقة تهيئة المراكز الأولية للعناقيد. القيمة الافتراضية هي "k-means++".
· `n_init`: عدد مرات تشغيل الخوارزمية بنقاط بداية مختلفة. القيمة الافتراضية هي "auto".
· `max_iter`: الحد الأقصى لعدد التكرارات لكل تشغيل للخوارزمية. القيمة الافتراضية هي 300.
· `tol`: قيمة التسامح (tolerance) لتحديد التقارب. القيمة الافتراضية هي 1e-4.
· `verbose`: مستوى التفاصيل المطبوعة أثناء التشغيل. القيمة الافتراضية هي 0 (لا تفاصيل).
· `random_state`: قيمة لتحديد العشوائية في التهيئة. القيمة الافتراضية هي `None`.
· `copy_x`: إذا كان `True`، يتم نسخ البيانات الأصلية قبل التشغيل. القيمة الافتراضية هي `True`.
· `algorithm`: الخوارزمية المستخدمة في K-Means. القيمة الافتراضية هي "lloyd".

**Code Description**: 
تقوم هذه الوظيفة بتهيئة كائن من فئة KMeans عن طريق استدعاء الدالة `__init__` من الفئة الأم (`super().__init__`) مع تمرير المعلمات الأساسية مثل `n_clusters`، `init`، `n_init`، `max_iter`، `tol`، `verbose`، و `random_state`. بعد ذلك، يتم تعيين المعلمات الإضافية `copy_x` و `algorithm` كخصائص للكائن الحالي. هذه المعلمات تحدد كيفية نسخ البيانات والخوارزمية المستخدمة في عملية التجميع.

**Note**: 
- تأكد من اختيار القيم المناسبة لمعلمات مثل `n_clusters` و `max_iter` بناءً على حجم البيانات وتعقيدها.
- إذا كنت تستخدم `random_state`، فسيتم ضمان تكرار النتائج عند تشغيل الكود أكثر من مرة.
- الخوارزمية "lloyd" هي الخوارزمية الكلاسيكية لـ K-Means، ولكن يمكن استبدالها بخوارزميات أخرى إذا كانت متاحة.
***
### FunctionDef _check_params_vs_input(self, X)
**_check_params_vs_input**: وظيفة `_check_params_vs_input` هي التحقق من توافق المعلمات المدخلة مع البيانات المدخلة وتعديلها إذا لزم الأمر.

**parameters**: معاملات هذه الوظيفة.
· `X`: مصفوفة أو مصفوفة متفرقة تحتوي على عينات البيانات التي سيتم تجميعها. يجب أن تكون البيانات بتنسيق C لتجنب نسخ الذاكرة إذا لم تكن متوافقة مع C.

**Code Description**: 
تقوم هذه الوظيفة بالتحقق من توافق المعلمات المدخلة مع البيانات المدخلة (`X`) وتعديلها إذا لزم الأمر. أولاً، تستدعي الوظيفة الوظيفة الأصلية `_check_params_vs_input` من الفئة الأم لتنفيذ التحقق الأساسي. بعد ذلك، تقوم بالتحقق من خوارزمية التجميع (`algorithm`) التي تم تحديدها. إذا كانت الخوارزمية المحددة هي `"elkan"` وعدد العناقيد (`n_clusters`) يساوي 1، فإن الوظيفة تقوم بإصدار تحذير (`RuntimeWarning`) يفيد بأن استخدام خوارزمية `"elkan"` لا معنى له في حالة وجود عنقود واحد فقط، وتقوم بتغيير الخوارزمية إلى `"lloyd"` بدلاً من ذلك.

هذه الوظيفة يتم استدعاؤها داخل وظيفة `fit` في فئة `KMeans`، حيث يتم التحقق من صحة البيانات والمعلمات قبل بدء عملية التجميع. هذا يضمن أن المعلمات المدخلة مناسبة للبيانات المقدمة وأن الخوارزمية المختارة تعمل بشكل صحيح.

**Note**: 
- يجب الانتباه إلى أن استخدام خوارزمية `"elkan"` غير مناسب عندما يكون عدد العناقيد 1، وسيتم تغييرها تلقائيًا إلى `"lloyd"`.
- يتم إصدار تحذير (`RuntimeWarning`) في حالة استخدام خوارزمية `"elkan"` مع عنقود واحد فقط.
***
### FunctionDef _warn_mkl_vcomp(self, n_active_threads)
**_warn_mkl_vcomp**: وظيفة `_warn_mkl_vcomp` هي إصدار تحذير عند وجود كل من `vcomp` و`mkl` معًا في نظام التشغيل Windows.

**parameters**: معاملات هذه الوظيفة.
· `n_active_threads`: عدد الخيوط النشطة (threads) التي يجب تعيينها في المتغير البيئي `OMP_NUM_THREADS` لتجنب تسرب الذاكرة.

**Code Description**: تقوم هذه الوظيفة بإصدار تحذير عند تشغيل خوارزمية KMeans على نظام Windows في حالة وجود كل من مكتبة `vcomp` و`mkl`. يُعرف عن KMeans أنها تعاني من تسرب في الذاكرة (memory leak) على نظام Windows عندما يكون عدد القطع (chunks) أقل من عدد الخيوط المتاحة (threads). يتم تفعيل هذا التسرب عند استخدام مكتبة MKL. لتجنب هذه المشكلة، تقترح الوظيفة تعيين المتغير البيئي `OMP_NUM_THREADS` بعدد الخيوط النشطة (`n_active_threads`) المحدد كمعامل للوظيفة. يتم إصدار هذا التحذير باستخدام الدالة `warnings.warn` من مكتبة `warnings` في بايثون.

**Note**: يجب الانتباه إلى أن هذا التحذير يظهر فقط عند تشغيل الكود على نظام Windows وفي حالة وجود كل من `vcomp` و`mkl`. تعيين المتغير البيئي `OMP_NUM_THREADS` بشكل صحيح يمكن أن يساعد في تجنب مشكلة تسرب الذاكرة.
***
### FunctionDef fit(self, X, y, sample_weight)
**fit**: وظيفة `fit` هي تنفيذ خوارزمية k-means لتجميع البيانات المدخلة.

**parameters**: معاملات هذه الوظيفة.
· `X`: مصفوفة أو مصفوفة متفرقة من الشكل (n_samples, n_features) تحتوي على العينات المراد تجميعها. يجب أن تكون البيانات بتنسيق C لتجنب نسخ الذاكرة إذا لم تكن متوافقة مع C.
· `y`: غير مستخدم، موجود هنا للحفاظ على توافق API.
· `sample_weight`: مصفوفة من الشكل (n_samples,) تحتوي على الأوزان لكل عينة في `X`. إذا كانت القيمة `None`، يتم تعيين وزن متساوٍ لجميع العينات.

**Code Description**: 
تقوم وظيفة `fit` بتنفيذ خوارزمية k-means لتجميع البيانات المدخلة (`X`). تبدأ العملية بالتحقق من صحة البيانات باستخدام `_validate_data`، حيث يتم التأكد من أن البيانات متوافقة مع التنسيق المطلوب (C-contiguous) وأنها من النوع الصحيح (float64 أو float32). بعد ذلك، يتم التحقق من توافق المعلمات المدخلة مع البيانات باستخدام `_check_params_vs_input`، حيث يتم تعديل الخوارزمية إذا كانت `algorithm` هي `"elkan"` وعدد العناقيد (`n_clusters`) يساوي 1.

بعد التحقق من صحة البيانات والمعلمات، يتم حساب الأوزان باستخدام `_check_sample_weight` إذا تم توفيرها. ثم يتم تحديد عدد الخيوط النشطة باستخدام `_openmp_effective_n_threads`. إذا كانت المراكز الأولية (`init`) عبارة عن مصفوفة، يتم التحقق من توافق شكلها مع البيانات باستخدام `_validate_center_shape`.

في حالة عدم كون البيانات متفرقة، يتم حساب متوسط البيانات (`X_mean`) وطرحه من البيانات لتحسين دقة حسابات المسافة. يتم أيضًا حساب القيم التربيعية للأبعاد الإقليدية (`x_squared_norms`) للبيانات.

بناءً على الخوارزمية المحددة (`algorithm`)، يتم اختيار الدالة المناسبة لتشغيل خوارزمية k-means (`_kmeans_single_elkan` أو `_kmeans_single_lloyd`). يتم تشغيل الخوارزمية عدة مرات (`n_init`) مع مراكز أولية مختلفة، ويتم اختيار أفضل نتيجة بناءً على قيمة القصور الذاتي (`inertia`).

في النهاية، يتم تخزين أفضل المراكز (`best_centers`)، التسميات (`best_labels`)، قيمة القصور الذاتي (`best_inertia`)، وعدد التكرارات (`best_n_iter`) في الكائن. إذا كان عدد العناقيد المميزة أقل من `n_clusters`، يتم إصدار تحذير (`ConvergenceWarning`).

يتم استدعاء هذه الوظيفة من خلال وظيفة `k_means` في المشروع، حيث يتم استخدامها لتشغيل خوارزمية k-means على البيانات المدخلة.

**Note**: 
- يجب أن تكون البيانات بتنسيق C لتجنب نسخ الذاكرة.
- إذا كانت الخوارزمية المحددة هي `"elkan"` وعدد العناقيد يساوي 1، سيتم تغييرها تلقائيًا إلى `"lloyd"`.
- يتم إصدار تحذير إذا كان عدد العناقيد المميزة أقل من `n_clusters`.

**Output Example**: 
```python
self.cluster_centers_ = array([[1.2, 3.4], [5.6, 7.8]])
self.labels_ = array([0, 1, 0, 1], dtype=int32)
self.inertia_ = 123.45
self.n_iter_ = 10
```
***
## FunctionDef _mini_batch_step(X, sample_weight, centers, centers_new, weight_sums, random_state, random_reassign, reassignment_ratio, verbose, n_threads)
**_mini_batch_step**: وظيفة `_mini_batch_step` هي تنفيذ تحديث تزايدي لمراكز العناقيد (centers) في خوارزمية MiniBatch K-Means.

**parameters**: معاملات هذه الوظيفة:
· `X`: مصفوفة أو مصفوفة sparse من الشكل (n_samples, n_features)، تمثل البيانات الأصلية. إذا كانت المصفوفة sparse، فيجب أن تكون بتنسيق CSR.
· `sample_weight`: مصفوفة من الشكل (n_samples,)، تمثل الأوزان لكل عينة في `X`.
· `centers`: مصفوفة من الشكل (n_clusters, n_features)، تمثل مراكز العناقيد قبل التحديث الحالي.
· `centers_new`: مصفوفة من الشكل (n_clusters, n_features)، تمثل مراكز العناقيد بعد التحديث الحالي. يتم تعديلها مباشرةً (in-place).
· `weight_sums`: مصفوفة من الشكل (n_clusters,)، تمثل عدد النقاط في كل عنقود. يتم تعديلها مباشرةً (in-place).
· `random_state`: كائن من نوع `RandomState`، يستخدم لتوليد الأرقام العشوائية لإعادة تعيين المراكز ذات العدد المنخفض.
· `random_reassign`: قيمة منطقية، القيمة الافتراضية هي `False`. إذا كانت `True`، يتم إعادة تعيين المراكز ذات العدد المنخفض بشكل عشوائي إلى نقاط بيانات أخرى.
· `reassignment_ratio`: عدد عشري، القيمة الافتراضية هي `0.01`. يتحكم في نسبة إعادة تعيين المراكز ذات العدد المنخفض.
· `verbose`: قيمة منطقية، القيمة الافتراضية هي `False`. تحكم في مستوى التفاصيل المطبوعة.
· `n_threads`: عدد صحيح، القيمة الافتراضية هي `1`. يمثل عدد خيوط OpenMP المستخدمة في الحساب.

**Code Description**: 
تقوم هذه الوظيفة بتنفيذ خطوة التحديث التزايدي في خوارزمية MiniBatch K-Means. أولاً، يتم تعيين التسميات (labels) لكل عينة إلى أقرب مركز عنقودي باستخدام وظيفة `_labels_inertia`، والتي تحسب أيضًا القصور الذاتي (inertia). بعد ذلك، يتم تحديث المراكز بناءً على التسميات المعينة. إذا كانت البيانات sparse، يتم استخدام وظيفة `_minibatch_update_sparse`، وإلا يتم استخدام `_minibatch_update_dense`.

إذا كانت المعلمة `random_reassign` مضبوطة على `True`، يتم إعادة تعيين المراكز ذات العدد المنخفض من النقاط بشكل عشوائي إلى نقاط بيانات أخرى. يتم تحديد المراكز التي سيتم إعادة تعيينها بناءً على نسبة `reassignment_ratio`. يتم أيضًا تعديل `weight_sums` للمراكز التي تم إعادة تعيينها لتجنب إعادة تعيينها فورًا مرة أخرى.

في المشروع، يتم استدعاء هذه الوظيفة من قبل وظيفتين رئيسيتين:
1. `fit`: تستخدم هذه الوظيفة `_mini_batch_step` لتحديث المراكز بشكل تزايدي أثناء عملية التدريب على دفعات صغيرة (mini-batches).
2. `partial_fit`: تستخدم هذه الوظيفة `_mini_batch_step` لتحديث المراكز عند تدريب النموذج على دفعة واحدة من البيانات.

**Note**: 
- إذا كانت البيانات sparse، فيجب أن تكون بتنسيق CSR لضمان الأداء الأمثل.
- يمكن التحكم في عدد الخيوط المستخدمة في الحساب عبر المعلمة `n_threads`، مما يسمح بتحسين الأداء على الأنظمة متعددة النوى.
- إعادة تعيين المراكز ذات العدد المنخفض يمكن أن تؤثر على وقت التقارب وجودة العناقيد النهائية.

**Output Example**: 
الإخراج هو القصور الذاتي (inertia) بعد تحديث المراكز. على سبيل المثال:
```python
inertia = 1234.56
```
حيث `inertia` هو عدد عشري يمثل مجموع مربعات المسافات بين العينات وأقرب مركز عنقودي لها.
## ClassDef MiniBatchKMeans
**MiniBatchKMeans**: وظيفة الفئة MiniBatchKMeans هي تنفيذ خوارزمية K-Means باستخدام دفعات صغيرة (mini-batches) لتجميع البيانات بشكل فعال، خاصة عند التعامل مع مجموعات بيانات كبيرة.

**السمات (Attributes)**:
· n_clusters: عدد العناقيد (clusters) المطلوب تكوينها. القيمة الافتراضية هي 8.
· init: طريقة تهيئة المراكز الأولية للعناقيد. يمكن أن تكون "k-means++"، "random"، أو دالة أو مصفوفة. القيمة الافتراضية هي "k-means++".
· max_iter: الحد الأقصى لعدد التكرارات على مجموعة البيانات الكاملة. القيمة الافتراضية هي 100.
· batch_size: حجم الدفعات الصغيرة (mini-batches). القيمة الافتراضية هي 1024.
· verbose: مستوى التفاصيل المطبوعة أثناء التشغيل. القيمة الافتراضية هي 0.
· compute_labels: إذا كان True، يتم حساب تسميات العناقيد وقيمة القصور الذاتي (inertia) بعد الانتهاء من التحسين. القيمة الافتراضية هي True.
· random_state: لتحديد العشوائية في التهيئة وإعادة تعيين العناقيد. القيمة الافتراضية هي None.
· tol: قيمة التسامح (tolerance) للتحكم في التوقف المبكر بناءً على التغيرات النسبية في المراكز. القيمة الافتراضية هي 0.0.
· max_no_improvement: عدد الدفعات المتتالية التي لا تحسن القصور الذاتي للتحكم في التوقف المبكر. القيمة الافتراضية هي 10.
· init_size: عدد العينات المستخدمة لتهيئة المراكز الأولية. القيمة الافتراضية هي None.
· n_init: عدد المرات التي يتم فيها تشغيل الخوارزمية بتهيئات أولية مختلفة. القيمة الافتراضية هي "auto".
· reassignment_ratio: نسبة إعادة تعيين المراكز ذات العدد القليل من النقاط. القيمة الافتراضية هي 0.01.

**وصف الكود**: 
الفئة MiniBatchKMeans هي تنفيذ لخوارزمية K-Means باستخدام دفعات صغيرة من البيانات، مما يجعلها مناسبة للتعامل مع مجموعات بيانات كبيرة. تعتمد هذه الفئة على الفئة الأساسية _BaseKMeans، التي توفر الهيكل العام والوظائف المشتركة لخوارزميات التجميع.

تتميز MiniBatchKMeans بقدرتها على التعامل مع البيانات الكبيرة عن طريق تقسيمها إلى دفعات صغيرة (mini-batches) وتحديث المراكز بشكل تدريجي. يتم ذلك من خلال دالة fit التي تقوم بتحديث المراكز باستخدام الدفعات الصغيرة، ودالة partial_fit التي تسمح بتحديث المراكز باستخدام دفعة واحدة فقط.

تحتوي الفئة على عدة معاملات للتحكم في سلوك الخوارزمية، مثل batch_size الذي يحدد حجم الدفعات الصغيرة، وmax_no_improvement الذي يتحكم في التوقف المبكر بناءً على تحسن القصور الذاتي. بالإضافة إلى ذلك، توفر الفئة إمكانية حساب تسميات العناقيد وقيمة القصور الذاتي بعد الانتهاء من التحسين.

تتعامل الفئة مع حالات خاصة مثل التحقق من وجود مشاكل في الذاكرة عند استخدام مكتبات معينة مثل MKL وvcomp (من خلال _check_mkl_vcomp و_warn_mkl_vcomp). كما توفر الفئة طرقًا لتنفيذ عمليات التجميع بشكل متزامن (fit_predict وfit_transform).

**ملاحظات**:
- يجب التأكد من أن عدد العينات أكبر من أو يساوي عدد العناقيد المطلوبة (n_clusters).
- عند استخدام init كدالة أو مصفوفة، يتم تنفيذ تهيئة واحدة فقط بغض النظر عن قيمة n_init.
- يتم إصدار تحذير إذا تم استخدام init كمصفوفة وقيمة n_init أكبر من 1.

**مثال للإخراج**:
عند استخدام الفئة للتنبؤ بالعناقيد، قد يكون الإخراج كالتالي:
```python
array([0, 1, 0, 2, 1], dtype=int32)
```
حيث يمثل كل عنصر في المصفوفة الفهرس الخاص بالعنقود الذي تنتمي إليه العينة المقابلة.
### FunctionDef __init__(self, n_clusters)
**__init__**: وظيفة `__init__` هي تهيئة كائن من فئة MiniBatchKMeans مع تحديد المعلمات الأولية اللازمة لتشغيل الخوارزمية.

**parameters**: معلمات هذه الوظيفة.
· `n_clusters`: عدد العناقيد (clusters) المطلوبة. القيمة الافتراضية هي 8.
· `init`: طريقة تهيئة المراكز الأولية للعناقيد. القيمة الافتراضية هي "k-means++".
· `max_iter`: الحد الأقصى لعدد التكرارات (iterations) التي ستقوم الخوارزمية بتنفيذها. القيمة الافتراضية هي 100.
· `batch_size`: حجم الدفعة (batch) المستخدمة في كل تكرار. القيمة الافتراضية هي 1024.
· `verbose`: مستوى التفاصيل المطبوعة أثناء التنفيذ. القيمة الافتراضية هي 0 (لا توجد تفاصيل).
· `compute_labels`: إذا كان `True`، سيتم حساب التسميات (labels) للبيانات المدخلة. القيمة الافتراضية هي `True`.
· `random_state`: البذرة (seed) المستخدمة لضمان تكرار النتائج. القيمة الافتراضية هي `None`.
· `tol`: قيمة التسامح (tolerance) لتحديد متى تتوقف الخوارزمية إذا لم يكن هناك تحسن كافٍ. القيمة الافتراضية هي 0.0.
· `max_no_improvement`: الحد الأقصى لعدد التكرارات التي يمكن أن تمر دون تحسن في النتيجة قبل إيقاف الخوارزمية. القيمة الافتراضية هي 10.
· `init_size`: حجم العينة الأولية المستخدمة لتهيئة المراكز. القيمة الافتراضية هي `None`.
· `n_init`: عدد مرات تشغيل الخوارزمية مع تهيئات مختلفة. القيمة الافتراضية هي "auto".
· `reassignment_ratio`: نسبة إعادة تعيين المراكز إذا كانت فارغة أو تحتوي على عدد قليل جدًا من العينات. القيمة الافتراضية هي 0.01.

**Code Description**: تقوم هذه الوظيفة بتهيئة كائن من فئة MiniBatchKMeans عن طريق استدعاء المُنشئ (constructor) للفئة الأم (super class) باستخدام المعلمات المحددة مثل `n_clusters`، `init`، `max_iter`، `verbose`، `random_state`، `tol`، و `n_init`. بعد ذلك، يتم تعيين القيم المتبقية للمعلمات مثل `max_no_improvement`، `batch_size`، `compute_labels`، `init_size`، و `reassignment_ratio` كخصائص للكائن. هذه المعلمات تُستخدم لضبط سلوك خوارزمية MiniBatchKMeans أثناء التشغيل.

**Note**: عند استخدام هذه الوظيفة، تأكد من فهم تأثير كل معلمة على أداء الخوارزمية. على سبيل المثال، زيادة `batch_size` قد يؤدي إلى تحسين الأداء ولكن قد يزيد من استخدام الذاكرة. بالإضافة إلى ذلك، يمكن استخدام `random_state` لضمان تكرار النتائج في حالات الاختبار.
***
### FunctionDef _check_params_vs_input(self, X)
**_check_params_vs_input**: وظيفة `_check_params_vs_input` هي التحقق من صحة المعلمات المدخلة مقارنةً ببيانات الإدخال `X` وتعديلها إذا لزم الأمر.

**parameters**: معاملات هذه الوظيفة.
· `X`: مصفوفة أو مصفوفة稀疏 تحتوي على بيانات التدريب التي سيتم استخدامها للتحقق من صحة المعلمات.

**Code Description**: تقوم هذه الوظيفة بالتحقق من صحة المعلمات المحددة في نموذج `MiniBatchKMeans` مقارنةً ببيانات الإدخال `X`. يتم تنفيذ الخطوات التالية:

1. **استدعاء الوظيفة الأصلية**: يتم استدعاء الوظيفة الأصلية `_check_params_vs_input` من الفئة الأم باستخدام `super()` للتحقق من المعلمات الأساسية. يتم تمرير `default_n_init=3` كقيمة افتراضية لعدد عمليات التهيئة.

2. **ضبط حجم الدفعة (`batch_size`)**: يتم ضبط حجم الدفعة (`batch_size`) بحيث لا يتجاوز عدد العينات في `X`. يتم ذلك باستخدام `min(self.batch_size, X.shape[0])`.

3. **ضبط حجم التهيئة (`init_size`)**: يتم التحقق من قيمة `init_size`، وهي حجم البيانات المستخدمة في عملية التهيئة الأولية. إذا كانت `init_size` غير محددة (`None`)، يتم تعيينها إلى ثلاثة أضعاف حجم الدفعة (`3 * self._batch_size`). إذا كانت هذه القيمة أقل من عدد العناقيد (`n_clusters`)، يتم تعيينها إلى ثلاثة أضعاف عدد العناقيد (`3 * self.n_clusters`). إذا كانت `init_size` محددة ولكنها أقل من عدد العناقيد، يتم إصدار تحذير (`RuntimeWarning`) وتعديل القيمة إلى ثلاثة أضعاف عدد العناقيد.

4. **التحقق من نسبة إعادة التخصيص (`reassignment_ratio`)**: يتم التحقق من أن قيمة `reassignment_ratio` أكبر من أو تساوي الصفر. إذا كانت القيمة سالبة، يتم إطلاق خطأ (`ValueError`).

**العلاقة مع الوظائف الأخرى في المشروع**: يتم استدعاء هذه الوظيفة من قبل وظيفتين رئيسيتين في المشروع:
- **`fit`**: يتم استدعاء `_check_params_vs_input` في بداية عملية التدريب (`fit`) للتحقق من صحة المعلمات قبل بدء عملية التجميع.
- **`partial_fit`**: يتم استدعاء هذه الوظيفة أيضًا في `partial_fit` عندما يتم تنفيذ التحديث على دفعة صغيرة من البيانات، وذلك للتأكد من أن المعلمات صالحة قبل إجراء التحديث.

**Note**: 
- يجب أن تكون قيمة `reassignment_ratio` أكبر من أو تساوي الصفر، وإلا سيتم إطلاق خطأ.
- يتم إصدار تحذير إذا كانت قيمة `init_size` أقل من عدد العناقيد، ويتم تعديلها تلقائيًا لضمان صحة العملية.
***
### FunctionDef _warn_mkl_vcomp(self, n_active_threads)
**_warn_mkl_vcomp**: وظيفة `_warn_mkl_vcomp` هي إصدار تحذير عند وجود كل من `vcomp` و`mkl` معًا في نظام التشغيل Windows.

**parameters**: معاملات هذه الوظيفة.
· `n_active_threads`: عدد الخيوط النشطة (threads) التي يجب تعيينها في المتغير البيئي `OMP_NUM_THREADS` لتجنب تسرب الذاكرة.

**Code Description**: تقوم هذه الوظيفة بإصدار تحذير عند تشغيل خوارزمية `MiniBatchKMeans` على نظام Windows مع وجود كل من `vcomp` و`mkl`. يُعرف عن `MiniBatchKMeans` أنه يعاني من تسرب في الذاكرة (memory leak) في هذه الحالة، خاصة عندما يكون عدد القطع (chunks) أقل من عدد الخيوط المتاحة (available threads). 

لتفادي هذه المشكلة، يمكن للمستخدم تعيين حجم الدفعة (`batch_size`) ليكون أكبر من أو يساوي حاصل ضرب عدد الخيوط (`self._n_threads`) في حجم القطعة (`CHUNK_SIZE`). بدلاً من ذلك، يمكن تعيين المتغير البيئي `OMP_NUM_THREADS` ليكون مساويًا لعدد الخيوط النشطة (`n_active_threads`).

يتم إصدار هذا التحذير باستخدام الدالة `warnings.warn`، والتي تعرض رسالة توضح المشكلة والحلول الممكنة.

**Note**: يجب على المستخدمين الذين يعملون على نظام Windows مع وجود `mkl` و`vcomp` أن ينتبهوا لهذا التحذير ويتخذوا الإجراءات اللازمة لتجنب تسرب الذاكرة.
***
### FunctionDef _mini_batch_convergence(self, step, n_steps, n_samples, centers_squared_diff, batch_inertia)
**_mini_batch_convergence**: وظيفة `_mini_batch_convergence` هي مساعدة في مراقبة تقارب خوارزمية Mini-Batch K-Means وتحديد ما إذا كان يجب إيقاف العملية مبكرًا بناءً على معايير محددة.

**المعلمات**:
· `step`: الخطوة الحالية في عملية التكرار.
· `n_steps`: العدد الإجمالي للخطوات المتوقعة.
· `n_samples`: العدد الإجمالي لعينات البيانات.
· `centers_squared_diff`: مجموع الفروق المربعة بين مراكز العناقيد القديمة والجديدة.
· `batch_inertia`: القصور الذاتي (inertia) للدفعة الحالية من البيانات.

**وصف الكود**: 
تقوم هذه الوظيفة بمراقبة تقارب خوارزمية Mini-Batch K-Means من خلال عدة خطوات:
1. **تطبيع القصور الذاتي**: يتم تقسيم `batch_inertia` على حجم الدفعة (`self._batch_size`) لجعل القيم قابلة للمقارنة حتى عند تغيير حجم الدفعة.
2. **تجاهل التكرار الأول**: يتم تجاهل التكرار الأول لأنه يمثل القصور الذاتي الناتج عن التهيئة الأولية.
3. **حساب المتوسط المتحرك الأسي (EWA)**: يتم حساب المتوسط المتحرك الأسي للقصور الذاتي لتقليل التباين العشوائي المحلي الناتج عن الدفعات الصغيرة. يتم تحديث المتوسط المتحرك باستخدام معامل `alpha` الذي يعتمد على حجم الدفعة وعدد العينات.
4. **مراقبة التغير في المراكز**: إذا كان التغير في مراكز العناقيد (`centers_squared_diff`) أقل من أو يساوي قيمة التسامح (`self._tol`)، يتم اعتبار أن الخوارزمية قد تقاربت ويتم إيقاف العملية مبكرًا.
5. **مراقبة تحسن القصور الذاتي**: إذا لم يتحسن المتوسط المتحرك الأسي للقصور الذاتي (`self._ewa_inertia`) لفترة معينة (يتم تحديدها بواسطة `self.max_no_improvement`)، يتم اعتبار أن الخوارزمية قد تقاربت ويتم إيقاف العملية مبكرًا.

يتم استدعاء هذه الوظيفة من داخل دالة `fit` في كائن `MiniBatchKMeans`، حيث يتم استخدامها لمراقبة التقارب أثناء عملية التكرار. إذا تم تحديد أن الخوارزمية قد تقاربت، يتم إيقاف عملية التكرار مبكرًا.

**ملاحظات**:
- يتم استخدام هذه الوظيفة بشكل أساسي لتحسين أداء الخوارزمية عن طريق إيقاف العملية مبكرًا عندما يتم تحقيق التقارب.
- يمكن تفعيل الوضع التفصيلي (`verbose`) لطباعة معلومات عن تقدم العملية والقصور الذاتي.

**مثال للإخراج**:
إذا تم تحقيق التقارب بناءً على تغير المراكز، قد يكون الإخراج كالتالي:
```
Converged (small centers change) at step 50/100
```
أو إذا تم تحقيق التقارب بناءً على عدم تحسن القصور الذاتي:
```
Converged (lack of improvement in inertia) at step 75/100
```
***
### FunctionDef _random_reassign(self)
**_random_reassign**: وظيفة `_random_reassign` هي التحقق مما إذا كان هناك حاجة لإعادة تعيين عشوائي للنقاط في عملية التجميع باستخدام خوارزمية MiniBatchKMeans.

**parameters**: لا تحتوي هذه الوظيفة على أي معاملات (parameters) محددة يتم تمريرها إليها مباشرةً، حيث تعتمد على الحالة الداخلية للكائن (self) فقط.

**Code Description**: 
تقوم هذه الوظيفة بالتحقق مما إذا كان يجب إجراء إعادة تعيين عشوائي للنقاط في عملية التجميع. يتم ذلك بناءً على شرطين رئيسيين:
1. إذا كانت هناك أي مجموعات (clusters) فارغة (أي أن عدد النقاط في مجموعة معينة يساوي صفرًا).
2. إذا تمت معالجة عدد من النقاط يساوي 10 أضعاف عدد المجموعات (`n_clusters`) منذ آخر إعادة تعيين.

تقوم الوظيفة بزيادة العداد `_n_since_last_reassign` بحجم الدفعة (`_batch_size`) في كل مرة يتم استدعاؤها. إذا تحقق أحد الشرطين المذكورين أعلاه، يتم إعادة تعيين العداد `_n_since_last_reassign` إلى الصفر وإرجاع القيمة `True` للإشارة إلى ضرورة إعادة التعيين. وإلا، يتم إرجاع `False`.

تُستخدم هذه الوظيفة بشكل أساسي في وظيفتي `fit` و`partial_fit` في فئة `MiniBatchKMeans`. في كلتا الوظيفتين، يتم استدعاء `_random_reassign` لتحديد ما إذا كان يجب إعادة تعيين النقاط بشكل عشوائي أثناء عملية التحديث التكراري لمراكز المجموعات. هذا يساعد في تجنب مشكلة المجموعات الفارغة ويحسن من دقة التجميع.

**Note**: 
- إعادة التعيين العشوائي تُستخدم لضمان عدم بقاء أي مجموعات فارغة، مما قد يؤثر سلبًا على جودة التجميع.
- يتم تنفيذ إعادة التعيين بشكل تلقائي بناءً على عدد النقاط التي تمت معالجتها وحالة المجموعات.

**Output Example**: 
مثال على القيمة المُرجعة من هذه الوظيفة:
```python
True  # إذا كان يجب إعادة التعيين
False  # إذا لم يكن هناك حاجة لإعادة التعيين
```
***
### FunctionDef fit(self, X, y, sample_weight)
**fit**: وظيفة `fit` هي حساب المراكز (centroids) للبيانات المدخلة `X` عن طريق تقسيمها إلى دفعات صغيرة (mini-batches).

**parameters**: معاملات هذه الوظيفة:
· `X`: مصفوفة أو مصفوفة sparse من الشكل (n_samples, n_features)، تمثل عينات التدريب التي سيتم تجميعها. يجب ملاحظة أن البيانات سيتم تحويلها إلى ترتيب C، مما قد يتسبب في نسخ الذاكرة إذا لم تكن البيانات متوافقة مع ترتيب C. إذا تم تمرير مصفوفة sparse، سيتم إنشاء نسخة إذا لم تكن بتنسيق CSR.
· `y`: يتم تجاهله، موجود هنا للحفاظ على اتساق واجهة البرمجة (API).
· `sample_weight`: مصفوفة من الشكل (n_samples,)، القيمة الافتراضية هي `None`. تمثل الأوزان لكل عينة في `X`. إذا كانت `None`، يتم تعيين وزن متساوٍ لجميع العينات. لا يتم استخدام `sample_weight` أثناء التهيئة إذا كانت `init` دالة أو مصفوفة مقدمة من المستخدم.

**Code Description**: 
تقوم وظيفة `fit` بحساب المراكز (centroids) للبيانات المدخلة `X` باستخدام خوارزمية MiniBatch K-Means. يتم ذلك عن طريق تقسيم البيانات إلى دفعات صغيرة (mini-batches) وتحديث المراكز بشكل تزايدي. تبدأ العملية بالتحقق من صحة البيانات المدخلة باستخدام `_validate_data`، والتي تضمن أن البيانات متوافقة مع الشكل المطلوب وأنها بتنسيق CSR إذا كانت sparse. بعد ذلك، يتم التحقق من صحة المعلمات المدخلة باستخدام `_check_params_vs_input`.

يتم بعد ذلك تهيئة المراكز الأولية باستخدام `_init_centroids`، والتي تقوم بتهيئة المراكز بناءً على الطريقة المحددة (مثل k-means++ أو التهيئة العشوائية). يتم حساب القصور الذاتي (inertia) على مجموعة تحقق (validation set) لتحديد أفضل تهيئة أولية.

بعد التهيئة، يتم تنفيذ عملية التحديث التكراري باستخدام `_mini_batch_step`، والتي تقوم بتحديث المراكز بناءً على الدفعات الصغيرة من البيانات. يتم مراقبة التقارب باستخدام `_mini_batch_convergence`، والتي تقوم بإيقاف العملية مبكرًا إذا تم تحقيق التقارب بناءً على تغير المراكز أو عدم تحسن القصور الذاتي.

في النهاية، يتم تخزين المراكز النهائية في `self.cluster_centers_`، ويتم حساب التسميات (labels) والقصور الذاتي النهائي إذا تم تحديد `compute_labels` على `True`.

**Note**: 
- يجب أن تكون البيانات المدخلة `X` متوافقة مع الشكل (n_samples, n_features).
- إذا كانت البيانات sparse، يجب أن تكون بتنسيق CSR لضمان الأداء الأمثل.
- يمكن التحكم في عدد الخيوط المستخدمة في الحساب عبر `n_threads`.

**Output Example**: 
الإخراج هو الكائن نفسه بعد التجهيز (fitted estimator). على سبيل المثال:
```python
<MiniBatchKMeans n_clusters=3>
```
***
### FunctionDef partial_fit(self, X, y, sample_weight)
**partial_fit**: وظيفة `partial_fit` هي تحديث تقدير خوارزمية K-Means على دفعة صغيرة واحدة من البيانات (mini-batch).

**parameters**: معاملات هذه الوظيفة:
· `X`: مصفوفة أو مصفوفة sparse من الشكل (n_samples, n_features)، تمثل عينات التدريب التي سيتم تجميعها. يجب ملاحظة أن البيانات سيتم تحويلها إلى تنسيق C، مما قد يتسبب في نسخ الذاكرة إذا لم تكن البيانات متوافقة مع تنسيق C. إذا تم تمرير مصفوفة sparse، سيتم إنشاء نسخة إذا لم تكن بتنسيق CSR.
· `y`: يتم تجاهله، موجود هنا للحفاظ على اتساق واجهة البرمجة (API).
· `sample_weight`: مصفوفة من الشكل (n_samples,)، القيمة الافتراضية هي `None`. تمثل الأوزان لكل عينة في `X`. إذا كانت القيمة `None`، يتم تعيين وزن متساوٍ لجميع العينات. لا يتم استخدام `sample_weight` أثناء التهيئة إذا كانت `init` دالة أو مصفوفة مقدمة من المستخدم.

**Code Description**: 
تقوم وظيفة `partial_fit` بتحديث مراكز العناقيد (clusters) بناءً على دفعة صغيرة من البيانات المدخلة `X`. يتم تنفيذ الخطوات التالية:

1. **التحقق من وجود المراكز**: يتم التحقق مما إذا كانت المراكز (`cluster_centers_`) موجودة بالفعل في الكائن. إذا لم تكن موجودة، يتم تهيئة المراكز باستخدام البيانات المدخلة.

2. **التحقق من صحة البيانات**: يتم التحقق من صحة البيانات المدخلة `X` باستخدام الدالة `_validate_data`. يتم التأكد من أن البيانات متوافقة مع التنسيق المطلوب (C-contiguous) وأنها من النوع `float64` أو `float32`. إذا كانت البيانات sparse، يتم التأكد من أنها بتنسيق CSR.

3. **تهيئة العشوائية والأوزان**: يتم تهيئة العشوائية (`_random_state`) إذا لم تكن موجودة بالفعل. يتم أيضًا التحقق من صحة `sample_weight` باستخدام الدالة `_check_sample_weight`.

4. **حساب القيم التربيعية للأبعاد**: يتم حساب القيم التربيعية للأبعاد الإقليدية لنقاط البيانات باستخدام الدالة `row_norms`.

5. **تهيئة المراكز إذا لزم الأمر**: إذا لم تكن المراكز موجودة، يتم التحقق من صحة المعلمات باستخدام الدالة `_check_params_vs_input`، ثم يتم تهيئة المراكز باستخدام الدالة `_init_centroids`. يتم أيضًا تهيئة العداد `_counts` و`_n_since_last_reassign`.

6. **تحديث المراكز**: يتم تحديث المراكز باستخدام الدالة `_mini_batch_step`، والتي تقوم بتعيين التسميات لكل عينة إلى أقرب مركز وتحديث المراكز بناءً على ذلك. إذا كانت المعلمة `random_reassign` مضبوطة على `True`، يتم إعادة تعيين المراكز ذات العدد المنخفض من النقاط بشكل عشوائي.

7. **حساب التسميات والقصور الذاتي**: إذا كانت المعلمة `compute_labels` مضبوطة على `True`، يتم حساب التسميات (`labels_`) والقصور الذاتي (`inertia_`) باستخدام الدالة `_labels_inertia_threadpool_limit`.

8. **تحديث عدد الخطوات**: يتم زيادة العداد `n_steps_` ليعكس عدد الخطوات التي تم تنفيذها.

9. **إرجاع الكائن المحدث**: يتم إرجاع الكائن المحدث (`self`) بعد الانتهاء من التحديث.

**Note**: 
- يجب أن تكون البيانات المدخلة `X` متوافقة مع تنسيق C لتجنب نسخ الذاكرة.
- إذا كانت البيانات sparse، يجب أن تكون بتنسيق CSR لضمان الأداء الأمثل.
- يمكن التحكم في عدد الخيوط المستخدمة في الحساب عبر المعلمة `n_threads`، مما يسمح بتحسين الأداء على الأنظمة متعددة النوى.

**Output Example**: 
الإخراج هو الكائن المحدث (`self`). على سبيل المثال:
```python
<MiniBatchKMeans n_clusters=3>
```
حيث يتم إرجاع الكائن بعد تحديث المراكز بناءً على البيانات المدخلة.
***
